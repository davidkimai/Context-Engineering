# Self-Refinement (自我优化)
## Adaptive Context Improvement Through Iterative Optimization (通过迭代优化实现自适应上下文改进)

> **Module 02.2** | *Context Engineering Course: From Foundations to Frontier Systems*
> **模块 02.2** | *上下文工程课程：从基础到前沿系统*
> 
> Building on [Context Engineering Survey](https://arxiv.org/pdf/2507.13334) | Advancing Self-Improving Context Systems
> 基于[上下文工程综述](https://arxiv.org/pdf/2507.13334) | 推进自我改进上下文系统

---

## Learning Objectives (学习目标)

By the end of this module, you will understand and implement:
- **Iterative Refinement Loops**: Self-improving context optimization cycles
- **Quality Assessment Mechanisms**: Automated evaluation of context effectiveness
- **Adaptive Learning Systems**: Context strategies that evolve based on feedback
- **Meta-Cognitive Frameworks**: Systems that reason about their own reasoning processes

在本模块结束时，您将理解并能实现：
- **迭代优化循环 (Iterative Refinement Loops)**: 自我改进的上下文优化周期
- **质量评估机制 (Quality Assessment Mechanisms)**: 上下文有效性的自动评估
- **自适应学习系统 (Adaptive Learning Systems)**: 基于反馈演进的上下文策略
- **元认知框架 (Meta-Cognitive Frameworks)**: 对自身推理过程进行推理的系统

---

## Conceptual Progression: From Static Context to Self-Improving Systems (概念演进：从静态上下文到自我改进系统)

Think of self-refinement like the process of becoming an expert writer - starting with rough drafts, then revising, editing, and continuously improving your writing based on feedback and experience.

可以将自我优化看作成为专家作家的过程——从草稿开始，然后根据反馈和经验进行修订、编辑和持续改进。

### Stage 1: Single-Pass Context Assembly (阶段 1：单遍上下文组装)
```
Input → Context Assembly → Output
(输入 → 上下文组装 → 输出)
```
**Context**: Like writing a first draft - you gather information, assemble it once, and produce output. No revision or improvement.
**上下文**: 就像写初稿——你收集信息，一次性组装，然后生成输出。没有修订或改进。

**Limitations** (局限性):
- Suboptimal context selection (次优的上下文选择)
- No learning from mistakes (无法从错误中学习)
- Static quality regardless of task requirements (无论任务要求如何，质量都是静态的)

### Stage 2: Error-Driven Revision (阶段 2：错误驱动的修订)
```
Input → Context Assembly → Output → Error Detection → Revision → Improved Output
(输入 → 上下文组装 → 输出 → 错误检测 → 修订 → 改进的输出)
```
**Context**: Like having an editor review your work and suggest specific improvements. The system detects problems and fixes them.
**上下文**: 就像让编辑审阅你的作品并提出具体改进建议。系统会检测问题并修复它们。

**Improvements** (改进):
- Identifies and corrects obvious mistakes (识别并纠正明显错误)
- Basic quality improvement loop (基本的质量改进循环)
- Reactive improvement based on detected issues (基于检测到的问题的反应式改进)

### Stage 3: Quality-Driven Iterative Refinement (阶段 3：质量驱动的迭代优化)
```
Input → Context Assembly → Quality Assessment → 
(输入 → 上下文组装 → 质量评估 →)
   ↓
If quality < threshold: (如果质量 < 阈值:)
   Context Refinement → Reassembly → Repeat (上下文优化 → 重新组装 → 重复)
Else: (否则:)
   Deliver Output (交付输出)
```
**Context**: Like a professional writer who revises multiple drafts, each time improving clarity, coherence, and impact based on quality metrics.
**上下文**: 就像一位专业作家会修改多份草稿，每次都根据质量指标提高清晰度、连贯性和影响力。

**Capabilities** (能力):
- Multi-dimensional quality evaluation (多维度质量评估)
- Iterative improvement until quality targets met (迭代改进直至达到质量目标)
- Systematic enhancement of context effectiveness (系统性地增强上下文有效性)

### Stage 4: Predictive Self-Optimization (阶段 4：预测性自我优化)
```
Historical Performance Analysis → Strategy Learning → 
(历史性能分析 → 策略学习 →)
Predictive Context Assembly → Quality Validation → 
(预测性上下文组装 → 质量验证 →)
Output Delivery + Strategy Update
(输出交付 + 策略更新)
```
**Context**: Like a master craftsperson who anticipates what will work before starting, based on years of experience and pattern recognition.
**上下文**: 就像一位大师级工匠，凭借多年的经验和模式识别，在开始之前就能预见到什么会奏效。

**Advanced Features** (高级特性):
- Learns optimal strategies from experience (从经验中学习最优策略)
- Predicts likely success before execution (在执行前预测可能的成功)
- Continuously evolves approach based on outcomes (根据结果不断演进方法)

### Stage 5: Meta-Cognitive Self-Awareness (阶段 5：元认知自我意识)
```
┌─────────────────────────────────────────────────────────────────┐
│                 META-COGNITIVE MONITORING                        │
│                 (元认知监控)                                     │
│  "How am I thinking? Is this approach optimal for this task?"   │
│  (“我正在如何思考？这种方法对这个任务来说是最优的吗？”)         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Self-Reflective Context Assembly                               │
│  (自我反思式上下文组装)                                         │
│  ↓                                                              │
│  Quality Prediction & Confidence Assessment                     │
│  (质量预测与置信度评估)                                         │
│  ↓                                                              │
│  Multi-Strategy Parallel Processing                             │
│  (多策略并行处理)                                               │
│  ↓                                                              │
│  Meta-Strategy Selection & Execution                            │
│  (元策略选择与执行)                                             │
│  ↓                                                              │
│  Outcome Analysis & Strategic Learning Integration              │
│  (结果分析与战略学习整合)                                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```
**Context**: Like a master teacher who not only knows the subject but understands their own thinking process, can adapt their teaching methods in real-time, and continuously improves their pedagogical approach.
**上下文**: 就像一位大师级教师，不仅了解学科知识，还了解自己的思维过程，能够实时调整教学方法，并不断改进其教学方法。

**Transcendent Capabilities** (超越性能力):
- Conscious awareness of own cognitive processes (对自身认知过程的有意识的觉察)
- Real-time strategy adaptation based on meta-analysis (基于元分析的实时策略调整)
- Teaching and transferring refinement capabilities (教授和转移优化能力)
- Emergent improvement beyond original design parameters (超越原始设计参数的涌现式改进)

---

## Mathematical Foundations (数学基础)

### Iterative Quality Optimization (迭代质量优化)
```
Context Refinement as Optimization Problem: (上下文优化作为优化问题)

C* = argmax_C Q(C, T, H)

Where: (其中：)
- C = context configuration (上下文配置)
- T = current task (当前任务)
- H = historical performance data (历史性能数据)
- Q(C, T, H) = quality function (质量函数)

Iterative Update Rule: (迭代更新规则)
C_{t+1} = C_t + α * ∇_C Q(C_t, T, H)

Where: (其中：)
- α = learning rate (学习率)
- ∇_C Q = gradient of quality function with respect to context parameters (质量函数关于上下文参数的梯度)
```
**Intuitive Explanation**: We're trying to find the best possible context by iteratively improving it, like climbing a hill where height represents quality. Each step moves us toward better context configuration based on what we've learned works.
**直观解释**: 我们试图通过迭代改进来找到最佳上下文，就像爬一座山，山的高度代表质量。每一步都根据我们学到的有效方法，将我们引向更好的上下文配置。

### Self-Assessment Confidence Modeling (自我评估置信度建模)
```
Confidence Estimation: P(Success | Context, Task, Strategy) (置信度估计)

Bayesian Update: (贝叶斯更新)
P(Strategy | Outcome) ∝ P(Outcome | Strategy) × P(Strategy)

Where: (其中：)
- P(Strategy) = prior belief in strategy effectiveness (对策略有效性的先验信念)
- P(Outcome | Strategy) = likelihood of outcome given strategy (给定策略下结果的可能性)
- P(Strategy | Outcome) = updated belief after observing outcome (观察到结果后更新的信念)
```
**Intuitive Explanation**: The system develops confidence in its own abilities by tracking which strategies work in which situations. Like building intuition through experience - you become more confident in approaches that have succeeded before.
**直观解释**: 系统通过跟踪哪些策略在哪些情况下有效，来建立对自己能力的信心。就像通过经验建立直觉——你会对以前成功过的方法更有信心。

### Meta-Learning Adaptation Rate (元学习适应率)
```
Strategy Evolution Rate: (策略演进率)
dS/dt = f(Performance_Gap, Exploration_Rate, Confidence_Level)

Where: (其中：)
- Performance_Gap = Target_Quality - Current_Quality (性能差距)
- Exploration_Rate = willingness to try new approaches (尝试新方法的意愿)
- Confidence_Level = certainty in current strategy effectiveness (当前策略有效性的确定性)

Adaptive Learning: (自适应学习)
Learning_Rate(t) = base_rate × (1 + Performance_Gap) × exp(-Confidence_Level)
```
**Intuitive Explanation**: The system learns faster when performance is poor (high performance gap) and confidence is low, but slows learning when performing well and confident. Like how humans learn - we experiment more when struggling and stick with approaches when they're working well.
**直观解释**: 当性能差（高性能差距）和信心低时，系统学习得更快，但在表现良好和有信心时学习速度会减慢。就像人类学习一样——我们在遇到困难时会更多地进行实验，而在方法行之有效时会坚持使用。

---

## Visual Self-Refinement Architecture (可视化自我优化架构)

```
┌─────────────────────────────────────────────────────────────────┐
│                  SELF-REFINEMENT PROCESSING PIPELINE            │
│                  (自我优化处理管道)                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Input Task & Requirements                                      │
│  (输入任务与需求)                                               │
│            │                                                    │
│            ▼                                                    │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │              INITIAL CONTEXT ASSEMBLY                   │   │
│  │              (初始上下文组装)                           │   │
│  │                                                         │   │
│  │  Strategy Selection → Information Retrieval →           │   │
│  │  (策略选择 → 信息检索 →)                                 │   │
│  │  Context Compilation → Initial Quality Assessment       │   │
│  │  (上下文编译 → 初始质量评估)                           │   │
│  │                                                         │   │
│  │  Output: [Initial Context + Confidence Score]          │   │
│  │  (输出：[初始上下文 + 置信度得分])                      │   │
│  └─────────────────────────────────────────────────────────┘   │
│            │                                                    │
│            ▼                                                    │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │              QUALITY EVALUATION SYSTEM                  │   │
│  │              (质量评估系统)                             │   │
│  │                                                         │   │
│  │  Multi-Dimensional Assessment:                          │   │
│  │  (多维度评估)                                           │   │
│  │  • Relevance Score     [████████░░] 80%                │   │
│  │  • (相关性得分)                                        │   │
│  │  • Completeness Score  [██████░░░░] 60%                │   │
│  │  • (完整性得分)                                        │   │
│  │  • Coherence Score     [██████████] 100%               │   │
│  │  • (连贯性得分)                                        │   │
│  │  • Efficiency Score    [███████░░░] 70%                │   │
│  │  • (效率得分)                                          │   │
│  │                                                         │   │
│  │  Overall Quality: [███████░░░] 77.5%                   │   │
│  │  (综合质量)                                            │   │
│  │  Threshold: 85% → REFINEMENT NEEDED                    │   │
│  │  (阈值：85% → 需要优化)                                 │   │
│  └─────────────────────────────────────────────────────────┘   │
│            │                                                    │
│            ▼                                                    │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │              REFINEMENT ENGINE                          │   │
│  │              (优化引擎)                                 │   │
│  │                                                         │   │
│  │  Gap Analysis:                                          │   │
│  │  (差距分析)                                             │   │
│  │  • Missing Information: [Specific topic gaps]          │   │
│  │  • (缺失信息：[具体主题差距])                           │   │
│  │  • Redundant Content: [Overlapping sections]          │   │
│  │  • (冗余内容：[重叠部分])                               │   │
│  │  • Logical Inconsistencies: [Contradiction points]     │   │
│  │  • (逻辑不一致：[矛盾点])                               │   │
│  │                                                         │   │
│  │  Improvement Actions:                                   │   │
│  │  (改进措施)                                             │   │
│  │  ✓ Retrieve additional sources                         │   │
│  │  ✓ (检索其他来源)                                      │   │
│  │  ✓ Remove redundant information                        │   │
│  │  ✓ (删除冗余信息)                                      │   │
│  │  ✓ Reorganize for better flow                          │   │
│  │  ✓ (为更好的流程重新组织)                              │   │
│  │  ✓ Enhance missing context bridges                     │   │
│  │  ✓ (增强缺失的上下文桥梁)                              │   │
│  └─────────────────────────────────────────────────────────┘   │
│            │                                                    │
│            ▼                                                    │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │              ITERATIVE OPTIMIZATION                     │   │
│  │              (迭代优化)                                 │   │
│  │                                                         │   │
│  │  Refinement Cycle #1: 77.5% → 82.3% (+4.8%)           │   │
│  │  (优化周期 #1)                                          │   │
│  │  Refinement Cycle #2: 82.3% → 86.1% (+3.8%)           │   │
│  │  (优化周期 #2)                                          │   │
│  │  Refinement Cycle #3: 86.1% → 87.2% (+1.1%)           │   │
│  │  (优化周期 #3)                                          │   │
│  │                                                         │   │
│  │  Quality Target Achieved: 87.2% ≥ 85% ✓                │   │
│  │  (质量目标已达到)                                      │   │
│  │  Convergence Detected: Improvement < 2%                │   │
│  │  (检测到收敛：改进 < 2%)                                │   │
│  └─────────────────────────────────────────────────────────┘   │
│            │                                                    │
│            ▼                                                    │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │              META-LEARNING INTEGRATION                  │   │
│  │              (元学习整合)                               │   │
│  │                                                         │   │
│  │  Strategy Performance Analysis:                         │   │
│  │  (策略性能分析)                                         │   │
│  │  • Initial Strategy: [Baseline approach] → 77.5%       │   │
│  │  • (初始策略：[基线方法] → 77.5%)                       │   │
│  │  • Refinement Pattern: [Gap-fill + reorganize] → +9.7% │   │
│  │  • (优化模式：[填补空白 + 重组] → +9.7%)                │   │
│  │  • Optimization Efficiency: [3 cycles] → Excellent     │   │
│  │  • (优化效率：[3 个周期] → 优秀)                        │   │
│  │                                                         │   │
│  │  Knowledge Update:                                      │   │
│  │  (知识更新)                                             │   │
│  │  → Store successful refinement pattern                 │   │
│  │  → (存储成功的优化模式)                                │   │
│  │  → Update strategy selection weights                   │   │
│  │  → (更新策略选择权重)                                  │   │
│  │  → Calibrate quality thresholds                        │   │
│  │  → (校准质量阈值)                                      │   │
│  └─────────────────────────────────────────────────────────┘   │
│            │                                                    │
│            ▼                                                    │
│  Final Output: [Optimally Refined Context] + [Learning Record] │
│  (最终输出：[优化后的上下文] + [学习记录])                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘

SYSTEM CHARACTERISTICS: (系统特性)
• Adaptive Quality Thresholds: Adjust based on task importance (自适应质量阈值：根据任务重要性进行调整)
• Multi-Strategy Refinement: Different improvement approaches for different gaps (多策略优化：针对不同差距采用不同的改进方法)
• Convergence Detection: Avoid infinite refinement loops (收敛检测：避免无限优化循环)
• Meta-Learning Integration: Improve refinement strategies over time (元学习整合：随时间改进优化策略)
• Performance Monitoring: Track refinement effectiveness and efficiency (性能监控：跟踪优化效果和效率)
```

---

## Software 3.0 Paradigm 1: Prompts (Self-Refinement Templates) (软件 3.0 范式 1：提示 (自我优化模板))

Strategic prompts help systems reason about their own context quality and improvement strategies.

战略性提示可帮助系统对其自身的上下文质量和改进策略进行推理。

### Quality Assessment and Refinement Template (质量评估和优化模板)

```markdown
# Context Quality Assessment and Refinement Framework (上下文质量评估和优化框架)

## Self-Assessment Protocol (自我评估协议)
You are a context refinement system evaluating and improving your own context assembly for optimal task performance.

您是一个上下文优化系统，负责评估和改进您自己的上下文组装，以实现最佳任务性能。

## Current Context Analysis (当前上下文分析)
**Original Context**: {assembled_context} (原始上下文)
**Task Requirements**: {task_description_and_success_criteria} (任务要求)
**Performance Target**: {quality_threshold_and_specific_metrics} (性能目标)

## Multi-Dimensional Quality Evaluation (多维度质量评估)

### 1. Relevance Assessment (1. 相关性评估)
**Evaluation Criteria**: How well does the context directly support task completion?
**评估标准**: 上下文在多大程度上直接支持任务完成？

**Relevance Analysis** (相关性分析):
- **Directly Relevant Information**: {percentage}% (直接相关信息)
  - List specific elements that directly answer the task requirements (列出直接回答任务要求的具体要素)
  - Identify information that provides essential background (识别提供必要背景的信息)
- **Tangentially Relevant Information**: {percentage}% (间接相关信息)
  - Note information that provides useful context but isn't essential (注意提供有用但非必要上下文的信息)
  - Assess whether this information helps or distracts from the main task (评估此信息是有助于还是分散了主要任务的注意力)
- **Irrelevant Information**: {percentage}% (不相关信息)
  - Identify information that doesn't contribute to task completion (识别对任务完成没有贡献的信息)
  - Mark content that could be removed without impact (标记可以无影响地删除的内容)

**Relevance Score**: {calculated_score}/10 (相关性得分)
**Improvement Opportunities**: {specific_areas_needing_better_relevance} (改进机会)

### 2. Completeness Assessment (2. 完整性评估)
**Evaluation Criteria**: Does the context contain all necessary information for task success?
**评估标准**: 上下文是否包含任务成功所需的所有必要信息？

**Completeness Analysis** (完整性分析):
- **Essential Information Present**: (存在的必要信息)
  - ✓ {list_present_essential_elements}
- **Essential Information Missing**: (缺失的必要信息)
  - ✗ {list_missing_critical_elements}
- **Supporting Information Gaps**: (支持信息差距)
  - {identify_missing_background_or_supporting_details}

**Completeness Score**: {calculated_score}/10 (完整性得分)
**Missing Information Priority** (缺失信息优先级):
  1. **Critical**: {must_have_information_for_task_success} (关键：任务成功必须具备的信息)
  2. **Important**: {significantly_improves_task_performance} (重要：显著提高任务性能的信息)
  3. **Helpful**: {provides_additional_context_or_validation} (有帮助：提供额外上下文或验证的信息)

### 3. Coherence Assessment (3. 连贯性评估)
**Evaluation Criteria**: Does the context flow logically and consistently?
**评估标准**: 上下文是否逻辑连贯、一致？

**Coherence Analysis** (连贯性分析):
- **Logical Flow**: {assessment_of_information_sequence_and_organization} (逻辑流程：信息序列和组织的评估)
- **Internal Consistency**: {check_for_contradictions_or_conflicting_information} (内部一致性：检查矛盾或冲突信息)
- **Conceptual Connections**: {evaluation_of_how_well_ideas_link_together} (概念连接：评估思想之间联系的紧密程度)
- **Transition Quality**: {assessment_of_bridges_between_different_topics} (过渡质量：评估不同主题之间桥梁的质量)

**Coherence Score**: {calculated_score}/10 (连贯性得分)
**Coherence Issues** (连贯性问题):
- **Logical Gaps**: {places_where_reasoning_jumps_or_connections_are_unclear} (逻辑空白：推理跳跃或连接不清晰的地方)
- **Contradictions**: {conflicting_information_that_needs_resolution} (矛盾：需要解决的冲突信息)
- **Disorganization**: {sections_that_would_benefit_from_reordering} (杂乱无章：可以从重新排序中受益的部分)

### 4. Efficiency Assessment (4. 效率评估)
**Evaluation Criteria**: Is the context optimally concise while maintaining quality?
**评估标准**: 在保持质量的同时，上下文是否达到了最佳的简洁性？

**Efficiency Analysis** (效率分析):
- **Information Density**: {ratio_of_useful_information_to_total_content} (信息密度：有用信息与总内容的比率)
- **Redundancy Level**: {percentage_of_repeated_or_overlapping_information} (冗余级别：重复或重叠信息的百分比)
- **Conciseness**: {assessment_of_whether_key_points_are_expressed_efficiently} (简洁性：评估关键点是否表达得高效)

**Efficiency Score**: {calculated_score}/10 (效率得分)
**Efficiency Improvements** (效率改进):
- **Redundancy Removal**: {specific_repeated_content_to_eliminate} (冗余消除：要消除的特定重复内容)
- **Compression Opportunities**: {verbose_sections_that_could_be_condensed} (压缩机会：可以精简的冗长部分)
- **Essential Expansion**: {areas_too_brief_that_need_more_detail} (必要扩展：过于简短需要更多细节的领域)

## Overall Quality Assessment (总体质量评估)

**Composite Quality Score** (综合质量得分):
```
Overall = (Relevance × 0.3 + Completeness × 0.3 + Coherence × 0.25 + Efficiency × 0.15)
Current Score: {calculated_overall_score}/10
Target Score: {quality_threshold}/10
Gap: {target_minus_current}
```

**Quality Determination** (质量判定):
- **Meets Standards** (Score ≥ {threshold}): ✓ / ✗ (符合标准 (得分 ≥ {阈值}))
- **Refinement Required**: {yes_no_based_on_score} (需要优化)
- **Priority Improvement Areas**: {top_2_3_areas_ranked_by_impact} (优先改进领域)

## Refinement Strategy Development (优化策略制定)

### Gap-Specific Improvement Plan (针对特定差距的改进计划)

#### For Relevance Gaps: (针对相关性差距)
```
IF relevance_score < threshold:
    ACTIONS:
    1. Remove irrelevant content: {specific_sections_to_remove}
    2. Replace tangential info with directly relevant info
    3. Refocus context on core task requirements
    4. Validate that every element serves the specific task
```

#### For Completeness Gaps: (针对完整性差距)
```  
IF completeness_score < threshold:
    ACTIONS:
    1. Research missing critical information: {specific_information_to_find}
    2. Retrieve additional relevant sources
    3. Fill knowledge gaps: {specific_gaps_to_address}
    4. Validate completeness against task requirements checklist
```

#### For Coherence Gaps: (针对连贯性差距)
```
IF coherence_score < threshold:
    ACTIONS:
    1. Reorganize information for logical flow: {new_organization_structure}
    2. Add transition sentences and connecting concepts
    3. Resolve contradictions: {specific_conflicts_to_address}
    4. Create clear conceptual bridges between sections
```

#### For Efficiency Gaps: (针对效率差距)
```
IF efficiency_score < threshold:
    ACTIONS:
    1. Remove redundant information: {specific_redundancies}
    2. Compress verbose sections while preserving meaning
    3. Combine related concepts for better density
    4. Ensure every word contributes value
```

## Iterative Refinement Protocol (迭代优化协议)

### Refinement Cycle Process: (优化周期过程)
1. **Implement Priority Improvements**: Address highest-impact gaps first (实施优先改进：首先解决影响最大的差距)
2. **Reassess Quality**: Re-evaluate all dimensions after changes (重新评估质量：更改后重新评估所有维度)
3. **Measure Improvement**: Calculate quality score change (衡量改进：计算质量得分变化)
4. **Convergence Check**: Determine if additional refinement is beneficial (收敛检查：确定额外的优化是否有益)
5. **Continue or Conclude**: Iterate until quality target achieved or diminishing returns (继续或结束：迭代直到达到质量目标或收益递减)

### Refinement Cycle Tracking: (优化周期跟踪)
```
Cycle 1: {initial_score} → {score_after_cycle_1} (Δ: {improvement})
Cycle 2: {score_after_cycle_1} → {score_after_cycle_2} (Δ: {improvement})
Cycle 3: {score_after_cycle_2} → {score_after_cycle_3} (Δ: {improvement})
...
```

### Convergence Criteria: (收敛标准)
- **Quality Target Met**: Overall score ≥ {threshold} (质量目标已达到)
- **Diminishing Returns**: Improvement per cycle < {minimum_improvement} (收益递减)
- **Maximum Cycles Reached**: Safety limit to prevent infinite loops (达到最大周期)
- **Resource Constraints**: Time or computational limits reached (资源限制)

## Meta-Learning Integration (元学习整合)

### Performance Pattern Analysis: (性能模式分析)
- **Successful Refinement Strategies**: {what_improvement_approaches_worked_best} (成功的优化策略)
- **Common Quality Gaps**: {patterns_in_what_typically_needs_improvement} (常见的质量差距)
- **Efficiency Patterns**: {how_many_cycles_typically_needed_for_different_task_types} (效率模式)

### Strategy Learning Updates: (策略学习更新)
- **Update Strategy Weights**: Increase probability of using successful approaches (更新策略权重：增加使用成功方法的概率)
- **Calibrate Quality Thresholds**: Adjust standards based on task outcomes (校准质量阈值：根据任务结果调整标准)
- **Improve Gap Detection**: Enhance ability to identify specific improvement needs (改进差距检测：增强识别特定改进需求的能力)
- **Optimize Refinement Sequences**: Learn better order for applying improvements (优化优化序列：学习应用改进的更好顺序)

## Refined Context Output (优化后的上下文输出)

**Final Refined Context**: {improved_context_after_refinement_cycles} (最终优化后的上下文)
**Quality Achievement**: (质量成就)
- Final Score: {final_quality_score}/10 (最终得分)
- Target Met: ✓ / ✗ (达到目标)
- Improvement: +{total_improvement_achieved} (改进)

**Refinement Summary**: (优化摘要)
- **Cycles Completed**: {number_of_refinement_iterations} (完成的周期)
- **Primary Improvements**: {main_enhancements_made} (主要改进)
- **Efficiency**: {refinement_cost_vs_benefit_assessment} (效率)

**Learning Integration**: {insights_gained_for_future_refinement_processes} (学习整合)
```

**Ground-up Explanation**: This template works like having a skilled editor review and improve a document through multiple drafts. The system systematically evaluates different aspects of quality (like an editor checking for clarity, completeness, flow, and conciseness), identifies specific problems, applies targeted improvements, and repeats until the content meets high standards. The meta-learning component helps the system get better at editing over time.
**基础解释**: 这个模板就像一个熟练的编辑，通过多轮草稿来审阅和改进文档。系统会系统地评估质量的各个方面（就像编辑检查清晰度、完整性、流畅度和简洁性一样），识别具体问题，应用有针对性的改进，并重复此过程，直到内容达到高标准。元学习组件帮助系统随着时间的推移在编辑方面做得更好。

### Meta-Cognitive Monitoring Template (Continued) (元认知监控模板 (续))

```xml
<meta_cognitive_template name="self_aware_context_processing">
  <intent>Enable system to monitor and improve its own thinking processes during context assembly</intent>
  <intent>使系统能够在上下文组装过程中监控和改进其自身的思维过程</intent>
  
  <cognitive_monitoring>
    <self_reflection_questions>
      <question category="strategy_awareness">
        What approach am I currently using to assemble this context, and why did I choose this approach?
      </question>
      <question category="effectiveness_assessment">
        How well is my current strategy working for this specific task and context?
      </question>
      <question category="alternative_consideration">
        What other approaches could I use, and might any of them be more effective?
      </question>
      <question category="confidence_calibration">
        How confident am I in the quality of my current context assembly, and is this confidence justified?
      </question>
    </self_reflection_questions>
    
    <thinking_process_analysis>
      <current_strategy>
        <strategy_name>{name_of_current_approach}</strategy_name>
        <strategy_rationale>{why_this_strategy_was_selected}</strategy_rationale>
        <strategy_assumptions>{what_assumptions_underlie_this_approach}</strategy_assumptions>
      </current_strategy>
      
      <performance_indicators>
        <positive_signals>
          {evidence_that_current_approach_is_working_well}
        </positive_signals>
        <warning_signals>
          {evidence_that_current_approach_may_have_problems}
        </warning_signals>
        <mixed_signals>
          {ambiguous_evidence_requiring_further_analysis}
        </mixed_signals>
      </performance_indicators>
      
      <confidence_assessment>
        <confidence_level>{numerical_confidence_score_0_to_1}</confidence_level>
        <confidence_basis>{reasons_for_current_confidence_level}</confidence_basis>
        <uncertainty_sources>{main_sources_of_doubt_or_uncertainty}</uncertainty_sources>
      </confidence_assessment>
    </thinking_process_analysis>
  </cognitive_monitoring>
  
  <strategy_comparison>
    <current_strategy_evaluation>
      <strengths>{what_current_strategy_does_well}</strengths>
      <weaknesses>{limitations_of_current_strategy}</weaknesses>
      <context_fit>{how_well_strategy_matches_current_task}</context_fit>
    </current_strategy_evaluation>
    
    <alternative_strategies>
      <alternative name="conservative_refinement">
        <description>Make minimal, high-confidence improvements</description>
        <advantages>Lower risk of introducing errors, preserves working elements</advantages>
        <disadvantages>May miss significant improvement opportunities</disadvantages>
        <switching_cost>Low - requires minimal changes to current approach</switching_cost>
      </alternative>
      
      <alternative name="aggressive_optimization">
        <description>Comprehensive restructuring for maximum quality</description>
        <advantages>Potential for significant quality improvements</advantages>
        <disadvantages>Higher risk, more resource intensive</disadvantages>
        <switching_cost>High - requires substantial rework of current context</switching_cost>
      </alternative>
      
      <alternative name="targeted_enhancement">
        <description>Focus improvements on identified weak areas only</description>
        <advantages>Efficient use of resources, addresses specific gaps</advantages>
        <disadvantages>May miss systemic issues or interaction effects</disadvantages>
        <switching_cost>Medium - selective modifications to current approach</switching_cost>
      </alternative>
    </alternative_strategies>
  </strategy_comparison>
  
  <meta_decision_making>
    <strategy_selection_criteria>
      <criterion name="task_criticality" weight="0.3">
        How important is optimal performance for this specific task?
      </criterion>
      <criterion name="resource_availability" weight="0.2">
        What computational and time resources are available for refinement?
      </criterion>
      <criterion name="risk_tolerance" weight="0.2">
        What is the acceptable risk of making the context worse through changes?
      </criterion>
      <criterion name="improvement_potential" weight="0.3">
        How much quality improvement is realistically achievable?
      </criterion>
    </strategy_selection_criteria>
    
    <decision_process>
      <step name="situation_analysis">
        Analyze current context quality, available resources, and task requirements
      </step>
      <step name="strategy_scoring">
        Score each potential strategy against selection criteria
      </step>
      <step name="uncertainty_assessment">
        Evaluate confidence in strategy effectiveness predictions
      </step>
      <step name="final_selection">
        Choose strategy with highest expected value considering uncertainty
      </step>
    </decision_process>
  </meta_decision_making>
  
  <execution_monitoring>
    <real_time_assessment>
      <progress_indicators>
        <indicator name="quality_trajectory">Track quality changes during refinement</indicator>
        <indicator name="efficiency_metrics">Monitor time and resource usage</indicator>
        <indicator name="unexpected_issues">Watch for problems not anticipated in planning</indicator>
      </progress_indicators>
      
      <adaptation_triggers>
        <trigger name="quality_degradation">
          <condition>Context quality decreases unexpectedly</condition>
          <response>Pause refinement, analyze cause, consider strategy change</response>
        </trigger>
        <trigger name="resource_exhaustion">
          <condition>Approaching time or computational limits</condition>
          <response>Prioritize remaining improvements, prepare for conclusion</response>
        </trigger>
        <trigger name="diminishing_returns">
          <condition>Improvement rate falls below threshold</condition>
          <response>Evaluate whether to continue or conclude refinement</response>
        </trigger>
      </adaptation_triggers>
    </real_time_assessment>
    
    <continuous_learning>
      <pattern_recognition>
        Identify recurring patterns in successful and unsuccessful refinement attempts
      </pattern_recognition>
      <strategy_calibration>
        Adjust confidence in different strategies based on observed outcomes
      </strategy_calibration>
      <meta_strategy_evolution>
        Improve the meta-cognitive monitoring process itself based on experience
      </meta_strategy_evolution>
    </continuous_learning>
  </execution_monitoring>
  
  <output_integration>
    <refined_context>
      {final_context_after_meta_cognitive_refinement}
    </refined_context>
    
    <meta_cognitive_report>
      <strategy_used>{selected_strategy_and_rationale}</strategy_used>
      <confidence_final>{final_confidence_in_result_quality}</confidence_final>
      <learning_insights>{key_insights_gained_about_refinement_process}</learning_insights>
      <future_improvements>{identified_ways_to_improve_meta_cognitive_process}</future_improvements>
    </meta_cognitive_report>
  </output_integration>
</meta_cognitive_template>
```

**Ground-up Explanation**: This meta-cognitive template is like having a master chess player who not only makes good moves but constantly thinks about their thinking process. They ask themselves "Why am I considering this strategy?", "How confident am I in this approach?", "What other strategies should I consider?", and "How can I improve my decision-making process?" The system becomes self-aware of its own cognitive processes and can optimize not just the immediate task, but how it approaches tasks in general.
**基础解释**: 这个元认知模板就像一位国际象棋大师，他不仅能走出好棋，而且不断思考自己的思维过程。他们会问自己：“我为什么考虑这个策略？”、“我对这个方法有多大信心？”、“我还应该考虑哪些其他策略？”以及“我如何改进我的决策过程？”。该系统能够自我意识到自己的认知过程，不仅可以优化当前任务，还可以优化其处理任务的通用方法。

---

## Software 3.0 Paradigm 2: Programming (Self-Refinement Implementation) (软件 3.0 范式 2：编程 (自我优化实现))

Programming provides the computational mechanisms that enable sophisticated self-refinement systems.

编程为复杂的自我优化系统提供了计算机制。

### Iterative Quality Optimization Engine (迭代质量优化引擎)

```python
import numpy as np
from typing import Dict, List, Tuple, Callable, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod
import time
from enum import Enum

class QualityDimension(Enum):
    """Different dimensions of context quality"""
    """上下文质量的不同维度"""
    RELEVANCE = "relevance"
    COMPLETENESS = "completeness" 
    COHERENCE = "coherence"
    EFFICIENCY = "efficiency"

@dataclass
class QualityAssessment:
    """Comprehensive quality assessment of context"""
    """上下文的综合质量评估"""
    relevance_score: float
    completeness_score: float
    coherence_score: float
    efficiency_score: float
    overall_score: float
    confidence: float
    assessment_details: Dict[str, any]
    improvement_suggestions: List[str]

@dataclass
class RefinementAction:
    """Specific refinement action to improve context"""
    """用于改进上下文的特定优化操作"""
    action_type: str
    target_dimension: QualityDimension
    description: str
    expected_improvement: float
    confidence: float
    implementation_cost: float
    priority: int

class QualityEvaluator(ABC):
    """Abstract base class for quality evaluation"""
    """质量评估的抽象基类"""
    
    @abstractmethod
    def evaluate(self, context: str, task: str, reference: Optional[str] = None) -> float:
        """Evaluate quality on specific dimension"""
        """评估特定维度的质量"""
        pass
    
    @abstractmethod
    def suggest_improvements(self, context: str, task: str) -> List[RefinementAction]:
        """Suggest specific improvements for this dimension"""
        """为此维度建议具体的改进"""
        pass

class RelevanceEvaluator(QualityEvaluator):
    """Evaluates how well context supports the specific task"""
    """评估上下文对特定任务的支持程度"""
    
    def __init__(self):
        self.key_term_weight = 0.4
        self.semantic_similarity_weight = 0.4
        self.task_alignment_weight = 0.2
        
    def evaluate(self, context: str, task: str, reference: Optional[str] = None) -> float:
        """Evaluate relevance of context to task"""
        """评估上下文与任务的相关性"""
        
        # Extract key terms from task
        # 从任务中提取关键词
        task_terms = self._extract_key_terms(task)
        context_terms = self._extract_key_terms(context)
        
        # Calculate term overlap
        # 计算术语重叠
        term_overlap = len(set(task_terms) & set(context_terms)) / len(set(task_terms))
        
        # Calculate semantic similarity (simplified)
        # 计算语义相似度（简化）
        semantic_sim = self._calculate_semantic_similarity(context, task)
        
        # Calculate task alignment (how well context addresses task requirements)
        # 计算任务对齐（上下文如何满足任务要求）
        task_alignment = self._calculate_task_alignment(context, task)
        
        # Weighted combination
        # 加权组合
        relevance_score = (
            self.key_term_weight * term_overlap +
            self.semantic_similarity_weight * semantic_sim +
            self.task_alignment_weight * task_alignment
        )
        
        return min(1.0, max(0.0, relevance_score))
    
    def suggest_improvements(self, context: str, task: str) -> List[RefinementAction]:
        """Suggest improvements for relevance"""
        """为相关性提出改进建议"""
        suggestions = []
        
        task_terms = self._extract_key_terms(task)
        context_terms = self._extract_key_terms(context)
        missing_terms = set(task_terms) - set(context_terms)
        
        if missing_terms:
            suggestions.append(RefinementAction(
                action_type="add_missing_content",
                target_dimension=QualityDimension.RELEVANCE,
                description=f"Add information about: {', '.join(missing_terms)}",
                expected_improvement=0.2 * len(missing_terms) / len(task_terms),
                confidence=0.8,
                implementation_cost=0.3,
                priority=1
            ))
        
        # Check for irrelevant content
        # 检查不相关内容
        irrelevant_ratio = self._calculate_irrelevant_content_ratio(context, task)
        if irrelevant_ratio > 0.2:
            suggestions.append(RefinementAction(
                action_type="remove_irrelevant_content",
                target_dimension=QualityDimension.RELEVANCE,
                description="Remove content not directly related to the task",
                expected_improvement=irrelevant_ratio * 0.5,
                confidence=0.7,
                implementation_cost=0.2,
                priority=2
            ))
        
        return suggestions
    
    def _extract_key_terms(self, text: str) -> List[str]:
        """Extract key terms from text"""
        """从文本中提取关键词"""
        # Simplified key term extraction
        # 简化的关键词提取
        words = text.lower().split()
        # Filter out common words and keep meaningful terms
        # 过滤掉常用词并保留有意义的术语
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with'}
        key_terms = [word for word in words if len(word) > 3 and word not in stop_words]
        return key_terms
    
    def _calculate_semantic_similarity(self, context: str, task: str) -> float:
        """Calculate semantic similarity between context and task"""
        """计算上下文和任务之间的语义相似度"""
        # Simplified semantic similarity calculation
        # 简化的语义相似度计算
        context_terms = set(self._extract_key_terms(context))
        task_terms = set(self._extract_key_terms(task))
        
        if not task_terms:
            return 0.0
        
        intersection = len(context_terms & task_terms)
        union = len(context_terms | task_terms)
        
        return intersection / union if union > 0 else 0.0
    
    def _calculate_task_alignment(self, context: str, task: str) -> float:
        """Calculate how well context addresses task requirements"""
        """计算上下文满足任务要求的程度"""
        # Simplified task alignment calculation
        # 简化的任务对齐计算
        task_lower = task.lower()
        context_lower = context.lower()
        
        # Look for task-specific indicators
        # 寻找特定于任务的指标
        task_indicators = ['analyze', 'compare', 'explain', 'summarize', 'evaluate']
        alignment_score = 0.0
        
        for indicator in task_indicators:
            if indicator in task_lower:
                # Check if context provides what this indicator requires
                # 检查上下文是否提供了此指标所需的内容
                if indicator == 'analyze' and ('analysis' in context_lower or 'factors' in context_lower):
                    alignment_score += 0.2
                elif indicator == 'compare' and ('comparison' in context_lower or 'versus' in context_lower):
                    alignment_score += 0.2
                elif indicator == 'explain' and ('explanation' in context_lower or 'because' in context_lower):
                    alignment_score += 0.2
                elif indicator == 'summarize' and ('summary' in context_lower or 'overview' in context_lower):
                    alignment_score += 0.2
                elif indicator == 'evaluate' and ('evaluation' in context_lower or 'assessment' in context_lower):
                    alignment_score += 0.2
        
        return min(1.0, alignment_score)
    
    def _calculate_irrelevant_content_ratio(self, context: str, task: str) -> float:
        """Calculate proportion of context that's irrelevant to task"""
        """计算与任务无关的上下文比例"""
        sentences = context.split('.')
        task_terms = set(self._extract_key_terms(task))
        
        irrelevant_sentences = 0
        for sentence in sentences:
            sentence_terms = set(self._extract_key_terms(sentence))
            if len(sentence_terms & task_terms) == 0 and len(sentence.strip()) > 20:
                irrelevant_sentences += 1
        
        return irrelevant_sentences / max(len(sentences), 1)

class CompletenessEvaluator(QualityEvaluator):
    """Evaluates whether context contains all necessary information"""
    """评估上下文是否包含所有必要信息"""
    
    def evaluate(self, context: str, task: str, reference: Optional[str] = None) -> float:
        """Evaluate completeness of context for task"""
        """评估任务上下文的完整性"""
        
        # Identify required information elements
        # 识别所需的信息元素
        required_elements = self._identify_required_elements(task)
        
        # Check presence of each element in context
        # 检查上下文中每个元素的存在
        present_elements = []
        for element in required_elements:
            if self._is_element_present(context, element):
                present_elements.append(element)
        
        # Calculate completeness ratio
        # 计算完整性比率
        completeness_ratio = len(present_elements) / len(required_elements) if required_elements else 1.0
        
        return completeness_ratio
    
    def suggest_improvements(self, context: str, task: str) -> List[RefinementAction]:
        """Suggest improvements for completeness"""
        """为完整性提出改进建议"""
        suggestions = []
        
        required_elements = self._identify_required_elements(task)
        missing_elements = []
        
        for element in required_elements:
            if not self._is_element_present(context, element):
                missing_elements.append(element)
        
        if missing_elements:
            for element in missing_elements:
                suggestions.append(RefinementAction(
                    action_type="add_missing_information",
                    target_dimension=QualityDimension.COMPLETENESS,
                    description=f"Add information about: {element}",
                    expected_improvement=1.0 / len(required_elements),
                    confidence=0.8,
                    implementation_cost=0.4,
                    priority=1
                ))
        
        return suggestions
    
    def _identify_required_elements(self, task: str) -> List[str]:
        """Identify information elements required for task completion"""
        """识别任务完成所需的信息元素"""
        # Simplified requirement identification
        # 简化的需求识别
        elements = []
        task_lower = task.lower()
        
        # Common information requirements based on task type
        # 基于任务类型的常见信息需求
        if 'analyze' in task_lower:
            elements.extend(['data', 'methodology', 'results', 'conclusions'])
        if 'compare' in task_lower:
            elements.extend(['similarities', 'differences', 'criteria'])
        if 'explain' in task_lower:
            elements.extend(['definition', 'mechanisms', 'examples'])
        if 'evaluate' in task_lower:
            elements.extend(['criteria', 'evidence', 'assessment', 'recommendation'])
        
        # Extract specific entities that should be covered
        # 提取应涵盖的特定实体
        entities = self._extract_entities(task)
        elements.extend(entities)
        
        return list(set(elements))  # Remove duplicates
    
    def _is_element_present(self, context: str, element: str) -> bool:
        """Check if required information element is present in context"""
        """检查上下文中是否存在所需的信息元素"""
        context_lower = context.lower()
        element_lower = element.lower()
        
        # Direct mention
        # 直接提及
        if element_lower in context_lower:
            return True
        
        # Synonyms and related terms (simplified)
        # 同义词和相关术语（简化）
        synonyms = {
            'data': ['information', 'statistics', 'numbers', 'evidence'],
            'methodology': ['method', 'approach', 'process', 'procedure'],
            'results': ['findings', 'outcomes', 'conclusions', 'output'],
            'similarities': ['common', 'shared', 'alike', 'same'],
            'differences': ['distinct', 'different', 'contrast', 'unlike']
        }
        
        if element_lower in synonyms:
            for synonym in synonyms[element_lower]:
                if synonym in context_lower:
                    return True
        
        return False
    
    def _extract_entities(self, task: str) -> List[str]:
        """Extract specific entities mentioned in task"""
        """从任务中提取提到的特定实体"""
        # Simplified entity extraction
        # 简化的实体提取
        words = task.split()
        entities = []
        
        # Look for capitalized words (potential proper nouns)
        # 寻找大写单词（可能是专有名词）
        for word in words:
            if word[0].isupper() and len(word) > 3:
                entities.append(word.lower())
        
        return entities

class CoherenceEvaluator(QualityEvaluator):
    """Evaluates logical flow and consistency of context"""
    """评估上下文的逻辑流程和一致性"""
    
    def evaluate(self, context: str, task: str, reference: Optional[str] = None) -> float:
        """Evaluate coherence of context"""
        """评估上下文的连贯性"""
        
        # Split into sentences for analysis
        # 分成句子进行分析
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        
        if len(sentences) < 2:
            return 1.0  # Single sentence is trivially coherent
        
        # Evaluate different aspects of coherence
        # 评估连贯性的不同方面
        logical_flow = self._evaluate_logical_flow(sentences)
        consistency = self._evaluate_consistency(sentences)
        connectivity = self._evaluate_connectivity(sentences)
        
        # Weighted combination
        # 加权组合
        coherence_score = (
            logical_flow * 0.4 +
            consistency * 0.3 +
            connectivity * 0.3
        )
        
        return coherence_score
    
    def suggest_improvements(self, context: str, task: str) -> List[RefinementAction]:
        """Suggest improvements for coherence"""
        """为连贯性提出改进建议"""
        suggestions = []
        
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        
        # Check for logical flow issues
        # 检查逻辑流程问题
        flow_issues = self._identify_flow_issues(sentences)
        if flow_issues:
            suggestions.append(RefinementAction(
                action_type="improve_logical_flow",
                target_dimension=QualityDimension.COHERENCE,
                description="Reorder sentences for better logical progression",
                expected_improvement=0.3,
                confidence=0.7,
                implementation_cost=0.2,
                priority=1
            ))
        
        # Check for consistency issues
        # 检查一致性问题
        consistency_issues = self._identify_consistency_issues(sentences)
        if consistency_issues:
            suggestions.append(RefinementAction(
                action_type="resolve_contradictions",
                target_dimension=QualityDimension.COHERENCE,
                description="Resolve contradictory or inconsistent information",
                expected_improvement=0.4,
                confidence=0.8,
                implementation_cost=0.3,
                priority=1
            ))
        
        # Check for connectivity issues
        # 检查连接性问题
        if len(sentences) > 3 and self._evaluate_connectivity(sentences) < 0.6:
            suggestions.append(RefinementAction(
                action_type="add_transitions",
                target_dimension=QualityDimension.COHERENCE,
                description="Add transition words and connecting phrases between ideas",
                expected_improvement=0.2,
                confidence=0.6,
                implementation_cost=0.1,
                priority=2
            ))
        
        return suggestions
    
    def _evaluate_logical_flow(self, sentences: List[str]) -> float:
        """Evaluate logical progression of ideas"""
        """评估思想的逻辑进展"""
        # Simplified logical flow evaluation
        # 简化的逻辑流程评估
        flow_score = 1.0
        
        for i in range(len(sentences) - 1):
            current_sentence = sentences[i].lower()
            next_sentence = sentences[i + 1].lower()
            
            # Check for abrupt topic changes (simplified)
            # 检查突然的主题变化（简化）
            current_terms = set(current_sentence.split())
            next_terms = set(next_sentence.split())
            
            overlap = len(current_terms & next_terms)
            if overlap == 0 and len(current_terms) > 3 and len(next_terms) > 3:
                flow_score -= 0.1  # Penalty for no connection
        
        return max(0.0, flow_score)
    
    def _evaluate_consistency(self, sentences: List[str]) -> float:
        """Evaluate internal consistency"""
        """评估内部一致性"""
        # Simplified consistency evaluation
        # 简化的一致性评估
        consistency_score = 1.0
        
        # Look for explicit contradictions (very simplified)
        # 寻找明显的矛盾（非常简化）
        contradiction_indicators = [
            ('is', 'is not'),
            ('can', 'cannot'),
            ('will', 'will not'),
            ('true', 'false'),
            ('always', 'never')
        ]
        
        context_lower = ' '.join(sentences).lower()
        
        for positive, negative in contradiction_indicators:
            if positive in context_lower and negative in context_lower:
                consistency_score -= 0.2
        
        return max(0.0, consistency_score)
    
    def _evaluate_connectivity(self, sentences: List[str]) -> float:
        """Evaluate how well sentences connect to each other"""
        """评估句子之间的连接程度"""
        # Simplified connectivity evaluation
        # 简化的连接性评估
        transition_words = [
            'however', 'therefore', 'furthermore', 'additionally', 'moreover',
            'consequently', 'nevertheless', 'meanwhile', 'similarly', 'in contrast'
        ]
        
        connectivity_indicators = 0
        total_transition_opportunities = len(sentences) - 1
        
        for sentence in sentences[1:]:  # Skip first sentence
            sentence_lower = sentence.lower()
            if any(word in sentence_lower for word in transition_words):
                connectivity_indicators += 1
        
        connectivity_score = connectivity_indicators / total_transition_opportunities if total_transition_opportunities > 0 else 1.0
        
        # Boost score if sentences naturally flow (shared terms)
        # 如果句子自然流畅（共享术语），则提高分数
        for i in range(len(sentences) - 1):
            current_terms = set(sentences[i].lower().split())
            next_terms = set(sentences[i + 1].lower().split())
            
            if len(current_terms & next_terms) > 0:
                connectivity_score += 0.1
        
        return min(1.0, connectivity_score)
    
    def _identify_flow_issues(self, sentences: List[str]) -> List[str]:
        """Identify specific logical flow issues"""
        """识别特定的逻辑流程问题"""
        issues = []
        
        for i in range(len(sentences) - 1):
            current_terms = set(sentences[i].lower().split())
            next_terms = set(sentences[i + 1].lower().split())
            
            # No shared terms might indicate flow issue
            # 没有共享术语可能表示流程问题
            if len(current_terms & next_terms) == 0:
                issues.append(f"Abrupt transition between sentences {i+1} and {i+2}")
        
        return issues
    
    def _identify_consistency_issues(self, sentences: List[str]) -> List[str]:
        """Identify specific consistency issues"""
        """识别特定的一致性问题"""
        issues = []
        
        # Very simplified consistency checking
        # 非常简化的一致性检查
        context_lower = ' '.join(sentences).lower()
        
        if 'is' in context_lower and 'is not' in context_lower:
            issues.append("Potential contradiction detected")
        
        if 'always' in context_lower and 'never' in context_lower:
            issues.append("Absolute statements may contradict")
        
        return issues

class EfficiencyEvaluator(QualityEvaluator):
    """Evaluates information density and conciseness"""
    """评估信息密度和简洁性"""
    
    def evaluate(self, context: str, task: str, reference: Optional[str] = None) -> float:
        """Evaluate efficiency of context"""
        """评估上下文的效率"""
        
        # Calculate information density
        # 计算信息密度
        information_density = self._calculate_information_density(context)
        
        # Calculate redundancy level
        # 计算冗余级别
        redundancy = self._calculate_redundancy(context)
        
        # Calculate conciseness
        # 计算简洁性
        conciseness = self._calculate_conciseness(context, task)
        
        # Weighted combination (higher is better)
        # 加权组合（越高越好）
        efficiency_score = (
            information_density * 0.4 +
            (1 - redundancy) * 0.3 +  # Lower redundancy is better
            conciseness * 0.3
        )
        
        return efficiency_score
    
    def suggest_improvements(self, context: str, task: str) -> List[RefinementAction]:
        """Suggest improvements for efficiency"""
        """为效率提出改进建议"""
        suggestions = []
        
        # Check redundancy
        # 检查冗余
        redundancy_level = self._calculate_redundancy(context)
        if redundancy_level > 0.2:
            suggestions.append(RefinementAction(
                action_type="remove_redundancy",
                target_dimension=QualityDimension.EFFICIENCY,
                description="Remove repeated or redundant information",
                expected_improvement=redundancy_level * 0.5,
                confidence=0.8,
                implementation_cost=0.2,
                priority=1
            ))
        
        # Check for verbose sections
        # 检查冗长部分
        verbose_ratio = self._identify_verbose_sections(context)
        if verbose_ratio > 0.3:
            suggestions.append(RefinementAction(
                action_type="compress_verbose_sections",
                target_dimension=QualityDimension.EFFICIENCY,
                description="Compress overly verbose sections while preserving meaning",
                expected_improvement=0.2,
                confidence=0.6,
                implementation_cost=0.3,
                priority=2
            ))
        
        return suggestions
    
    def _calculate_information_density(self, context: str) -> float:
        """Calculate information density (unique concepts per word)"""
        """计算信息密度（每个单词的独特概念）"""
        words = context.lower().split()
        unique_words = set(words)
        
        # Remove common stop words for better density calculation
        # 删除常用停用词以获得更好的密度计算
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'is', 'are', 'was', 'were'}
        meaningful_words = [word for word in unique_words if word not in stop_words]
        
        if not words:
            return 0.0
        
        density = len(meaningful_words) / len(words)
        return min(1.0, density * 2)  # Scale and cap at 1.0
    
    def _calculate_redundancy(self, context: str) -> float:
        """Calculate redundancy level in context"""
        """计算上下文中的冗余级别"""
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        
        if len(sentences) < 2:
            return 0.0
        
        # Check for repeated phrases
        # 检查重复短语
        redundancy_score = 0.0
        phrase_counts = {}
        
        for sentence in sentences:
            words = sentence.lower().split()
            # Check 3-word phrases
            # 检查 3 词短语
            for i in range(len(words) - 2):
                phrase = ' '.join(words[i:i+3])
                phrase_counts[phrase] = phrase_counts.get(phrase, 0) + 1
        
        # Calculate redundancy based on repeated phrases
        # 基于重复短语计算冗余
        repeated_phrases = sum(1 for count in phrase_counts.values() if count > 1)
        total_phrases = len(phrase_counts)
        
        if total_phrases > 0:
            redundancy_score = repeated_phrases / total_phrases
        
        return redundancy_score
    
    def _calculate_conciseness(self, context: str, task: str) -> float:
        """Calculate conciseness relative to task requirements"""
        """计算相对于任务要求的简洁性"""
        context_length = len(context.split())
        
        # Estimate optimal length based on task complexity (simplified)
        # 根据任务复杂度估算最佳长度（简化）
        task_complexity = self._estimate_task_complexity(task)
        optimal_length = task_complexity * 50  # 50 words per complexity unit
        
        if context_length <= optimal_length:
            return 1.0
        else:
            # Penalty for excessive length
            # 对过长长度的惩罚
            excess_ratio = (context_length - optimal_length) / optimal_length
            conciseness = max(0.0, 1.0 - excess_ratio * 0.5)
            return conciseness
    
    def _estimate_task_complexity(self, task: str) -> int:
        """Estimate task complexity (1-10 scale)"""
        """估算任务复杂度（1-10级）"""
        task_lower = task.lower()
        complexity = 1
        
        # Add complexity for different task types
        # 为不同任务类型增加复杂度
        complex_indicators = ['analyze', 'compare', 'evaluate', 'synthesize']
        for indicator in complex_indicators:
            if indicator in task_lower:
                complexity += 2
        
        # Add complexity for multiple requirements
        # 为多个需求增加复杂度
        requirement_indicators = ['and', 'also', 'additionally', 'furthermore']
        for indicator in requirement_indicators:
            if indicator in task_lower:
                complexity += 1
        
        return min(10, complexity)
    
    def _identify_verbose_sections(self, context: str) -> float:
        """Identify overly verbose sections"""
        """识别过于冗长的部分"""
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        verbose_sentences = 0
        
        for sentence in sentences:
            words = sentence.split()
            # Consider sentences with >30 words as potentially verbose
            # 认为超过 30 个单词的句子可能冗长
            if len(words) > 30:
                verbose_sentences += 1
        
        return verbose_sentences / len(sentences) if sentences else 0.0

class SelfRefinementEngine:
    """Main engine for iterative context self-refinement"""
    """用于迭代上下文自我优化的主引擎"""
    
    def __init__(self, quality_threshold: float = 0.8, max_iterations: int = 5):
        self.quality_threshold = quality_threshold
        self.max_iterations = max_iterations
        self.min_improvement = 0.02  # Minimum improvement to continue
        
        # Initialize quality evaluators
        # 初始化质量评估器
        self.evaluators = {
            QualityDimension.RELEVANCE: RelevanceEvaluator(),
            QualityDimension.COMPLETENESS: CompletenessEvaluator(),
            QualityDimension.COHERENCE: CoherenceEvaluator(),
            QualityDimension.EFFICIENCY: EfficiencyEvaluator()
        }
        
        # Quality dimension weights
        # 质量维度权重
        self.dimension_weights = {
            QualityDimension.RELEVANCE: 0.3,
            QualityDimension.COMPLETENESS: 0.3,
            QualityDimension.COHERENCE: 0.25,
            QualityDimension.EFFICIENCY: 0.15
        }
        
        # Learning and adaptation
        # 学习与适应
        self.performance_history = []
        self.strategy_effectiveness = {}
        
    def refine_context(self, initial_context: str, task: str, 
                      reference: Optional[str] = None) -> Tuple[str, QualityAssessment, Dict]:
        """Main refinement process with iterative improvement"""
        """具有迭代改进的主要优化过程"""
        
        print(f"Starting context refinement process...")
        print(f"Initial context length: {len(initial_context)} characters")
        
        current_context = initial_context
        refinement_history = []
        
        # Initial quality assessment
        # 初始质量评估
        initial_assessment = self.assess_quality(current_context, task, reference)
        print(f"Initial quality score: {initial_assessment.overall_score:.3f}")
        
        refinement_history.append({
            'iteration': 0,
            'context': current_context,
            'assessment': initial_assessment,
            'actions_taken': []
        })
        
        # Refinement iterations
        # 优化迭代
        for iteration in range(1, self.max_iterations + 1):
            print(f"\nRefinement iteration {iteration}:")
            
            # Check if quality threshold already met
            # 检查是否已达到质量阈值
            current_assessment = self.assess_quality(current_context, task, reference)
            
            if current_assessment.overall_score >= self.quality_threshold:
                print(f"Quality threshold {self.quality_threshold:.3f} achieved!")
                break
            
            # Generate improvement actions
            # 生成改进措施
            improvement_actions = self._generate_improvement_actions(
                current_context, task, current_assessment
            )
            
            if not improvement_actions:
                print("No improvement actions available.")
                break
            
            # Apply improvements
            # 应用改进
            improved_context, actions_applied = self._apply_improvements(
                current_context, improvement_actions, task
            )
            
            # Assess improvement
            # 评估改进
            new_assessment = self.assess_quality(improved_context, task, reference)
            improvement = new_assessment.overall_score - current_assessment.overall_score
            
            print(f"Quality improvement: {improvement:+.3f} ({current_assessment.overall_score:.3f} → {new_assessment.overall_score:.3f})")
            
            # Check for convergence
            # 检查收敛性
            if improvement < self.min_improvement:
                print(f"Convergence detected (improvement < {self.min_improvement:.3f})")
                break
            
            # Update for next iteration
            # 为下一次迭代更新
            current_context = improved_context
            refinement_history.append({
                'iteration': iteration,
                'context': current_context,
                'assessment': new_assessment,
                'actions_taken': actions_applied,
                'improvement': improvement
            })
            
            # Learn from this iteration
            # 从这次迭代中学习
            self._update_learning(actions_applied, improvement)
        
        # Final assessment
        # 最终评估
        final_assessment = self.assess_quality(current_context, task, reference)
        
        # Generate refinement report
        # 生成优化报告
        refinement_report = self._generate_refinement_report(refinement_history, initial_assessment, final_assessment)
        
        print(f"\nRefinement complete!")
        print(f"Final quality score: {final_assessment.overall_score:.3f}")
        print(f"Total improvement: {final_assessment.overall_score - initial_assessment.overall_score:+.3f}")
        
        return current_context, final_assessment, refinement_report
    
    def assess_quality(self, context: str, task: str, reference: Optional[str] = None) -> QualityAssessment:
        """Comprehensive quality assessment across all dimensions"""
        """跨所有维度的综合质量评估"""
        
        dimension_scores = {}
        all_suggestions = []
        assessment_details = {}
        
        # Evaluate each quality dimension
        # 评估每个质量维度
        for dimension, evaluator in self.evaluators.items():
            score = evaluator.evaluate(context, task, reference)
            suggestions = evaluator.suggest_improvements(context, task)
            
            dimension_scores[dimension] = score
            all_suggestions.extend(suggestions)
            assessment_details[dimension.value] = {
                'score': score,
                'suggestions_count': len(suggestions)
            }
        
        # Calculate overall score using weighted average
        # 使用加权平均计算总分
        overall_score = sum(
            dimension_scores[dim] * weight 
            for dim, weight in self.dimension_weights.items()
        )
        
        # Calculate confidence based on score distribution
        # 根据分数分布计算置信度
        score_variance = np.var(list(dimension_scores.values()))
        confidence = max(0.5, 1.0 - score_variance)  # Lower variance = higher confidence
        
        return QualityAssessment(
            relevance_score=dimension_scores[QualityDimension.RELEVANCE],
            completeness_score=dimension_scores[QualityDimension.COMPLETENESS],
            coherence_score=dimension_scores[QualityDimension.COHERENCE],
            efficiency_score=dimension_scores[QualityDimension.EFFICIENCY],
            overall_score=overall_score,
            confidence=confidence,
            assessment_details=assessment_details,
            improvement_suggestions=[action.description for action in all_suggestions]
        )
    
    def _generate_improvement_actions(self, context: str, task: str, 
                                    assessment: QualityAssessment) -> List[RefinementAction]:
        """Generate prioritized list of improvement actions"""
        """生成优先的改进措施列表"""
        
        all_actions = []
        
        # Get suggestions from each evaluator
        # 从每个评估器获取建议
        for dimension, evaluator in self.evaluators.items():
            actions = evaluator.suggest_improvements(context, task)
            all_actions.extend(actions)
        
        # Prioritize actions based on expected improvement and historical effectiveness
        # 根据预期改进和历史有效性对行动进行优先排序
        prioritized_actions = self._prioritize_actions(all_actions, assessment)
        
        return prioritized_actions[:3]  # Return top 3 actions to avoid overwhelming changes
    
    def _prioritize_actions(self, actions: List[RefinementAction], 
                          assessment: QualityAssessment) -> List[RefinementAction]:
        """Prioritize refinement actions based on multiple criteria"""
        """根据多个标准对优化操作进行优先排序"""
        
        for action in actions:
            # Calculate priority score
            # 计算优先级分数
            expected_value = action.expected_improvement * action.confidence
            cost_factor = 1.0 / (1.0 + action.implementation_cost)
            
            # Apply historical effectiveness if available
            # 如果可用，则应用历史有效性
            historical_effectiveness = self.strategy_effectiveness.get(action.action_type, 0.5)
            
            # Boost actions targeting dimensions with low scores
            # 提升针对低分维度的行动
            dimension_boost = 1.0
            if action.target_dimension == QualityDimension.RELEVANCE:
                dimension_boost = 1.0 + (0.8 - assessment.relevance_score)
            elif action.target_dimension == QualityDimension.COMPLETENESS:
                dimension_boost = 1.0 + (0.8 - assessment.completeness_score)
            elif action.target_dimension == QualityDimension.COHERENCE:
                dimension_boost = 1.0 + (0.8 - assessment.coherence_score)
            elif action.target_dimension == QualityDimension.EFFICIENCY:
                dimension_boost = 1.0 + (0.8 - assessment.efficiency_score)
            
            # Final priority score
            # 最终优先级分数
            action.priority = expected_value * cost_factor * historical_effectiveness * dimension_boost
        
        # Sort by priority (highest first)
        # 按优先级排序（最高在前）
        return sorted(actions, key=lambda a: a.priority, reverse=True)
    
    def _apply_improvements(self, context: str, actions: List[RefinementAction], 
                          task: str) -> Tuple[str, List[str]]:
        """Apply improvement actions to context"""
        """将改进措施应用于上下文"""
        
        improved_context = context
        actions_applied = []
        
        for action in actions:
            try:
                # Apply specific improvement based on action type
                # 根据操作类型应用特定的改进
                if action.action_type == "add_missing_content":
                    improved_context = self._add_missing_content(improved_context, action, task)
                elif action.action_type == "remove_irrelevant_content":
                    improved_context = self._remove_irrelevant_content(improved_context, task)
                elif action.action_type == "add_missing_information":
                    improved_context = self._add_missing_information(improved_context, action, task)
                elif action.action_type == "improve_logical_flow":
                    improved_context = self._improve_logical_flow(improved_context)
                elif action.action_type == "resolve_contradictions":
                    improved_context = self._resolve_contradictions(improved_context)
                elif action.action_type == "add_transitions":
                    improved_context = self._add_transitions(improved_context)
                elif action.action_type == "remove_redundancy":
                    improved_context = self._remove_redundancy(improved_context)
                elif action.action_type == "compress_verbose_sections":
                    improved_context = self._compress_verbose_sections(improved_context)
                
                actions_applied.append(action.description)
                print(f"  Applied: {action.description}")
                
            except Exception as e:
                print(f"  Failed to apply: {action.description} - {str(e)}")
        
        return improved_context, actions_applied
    
    def _add_missing_content(self, context: str, action: RefinementAction, task: str) -> str:
        """Add missing content identified in the action"""
        """添加操作中识别的缺失内容"""
        # Simplified implementation - in practice would use retrieval or generation
        # 简化的实现 - 实践中会使用检索或生成
        missing_info = action.description.split(": ")[1] if ": " in action.description else "additional information"
        
        addition = f"\n\nRegarding {missing_info}: This aspect requires further elaboration to fully address the task requirements."
        return context + addition
    
    def _remove_irrelevant_content(self, context: str, task: str) -> str:
        """Remove content not directly relevant to the task"""
        """删除与任务不直接相关的内容"""
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        task_terms = set(task.lower().split())
        
        relevant_sentences = []
        for sentence in sentences:
            sentence_terms = set(sentence.lower().split())
            # Keep sentences that share terms with the task or are very short (likely connective)
            # 保留与任务共享术语或非常短（可能是连接词）的句子
            if len(sentence_terms & task_terms) > 0 or len(sentence.split()) < 5:
                relevant_sentences.append(sentence)
        
        return '. '.join(relevant_sentences) + '.'
    
    def _add_missing_information(self, context: str, action: RefinementAction, task: str) -> str:
        """Add specific missing information"""
        """添加特定的缺失信息"""
        # Simplified - would integrate with knowledge retrieval in practice
        # 简化 - 实践中会与知识检索集成
        info_type = action.description.split(": ")[1] if ": " in action.description else "information"
        addition = f" Additionally, {info_type} should be considered in this context."
        return context + addition
    
    def _improve_logical_flow(self, context: str) -> str:
        """Improve the logical flow of the context"""
        """改善上下文的逻辑流程"""
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        
        # Simple reordering based on sentence connections
        # 基于句子连接的简单重新排序
        # In practice, would use more sophisticated discourse analysis
        # 实践中会使用更复杂的话语分析
        if len(sentences) > 2:
            # Move sentences with "However" or "Therefore" to appropriate positions
            # 将带有“However”或“Therefore”的句子移至适当位置
            reordered = []
            contrasts = []
            conclusions = []
            regular = []
            
            for sentence in sentences:
                sentence_lower = sentence.lower()
                if sentence_lower.startswith('however') or 'in contrast' in sentence_lower:
                    contrasts.append(sentence)
                elif sentence_lower.startswith('therefore') or 'consequently' in sentence_lower:
                    conclusions.append(sentence)
                else:
                    regular.append(sentence)
            
            # Reassemble: regular statements, then contrasts, then conclusions
            # 重新组合：常规陈述，然后是对比，然后是结论
            reordered = regular + contrasts + conclusions
            return '. '.join(reordered) + '.'
        
        return context
    
    def _resolve_contradictions(self, context: str) -> str:
        """Resolve contradictory information"""
        """解决矛盾信息"""
        # Simplified contradiction resolution
        # 简化的矛盾解决
        # In practice, would use more sophisticated conflict resolution
        # 实践中会使用更复杂的冲突解决
        
        # Remove obvious contradictory pairs
        # 删除明显的矛盾对
        contradiction_pairs = [
            ('is not', 'is'),
            ('cannot', 'can'),
            ('never', 'always'),
            ('impossible', 'possible')
        ]
        
        resolved_context = context
        for negative, positive in contradiction_pairs:
            if negative in resolved_context and positive in resolved_context:
                # Keep the more specific or qualified statement
                # 保留更具体或限定的陈述
                if f"generally {positive}" in resolved_context or f"usually {positive}" in resolved_context:
                    resolved_context = resolved_context.replace(f" {negative} ", f" is generally not ")
                else:
                    resolved_context = resolved_context.replace(f" {negative} ", f" may not be ")
        
        return resolved_context
    
    def _add_transitions(self, context: str) -> str:
        """Add transition words to improve connectivity"""
        """添加过渡词以改善连接性"""
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        
        if len(sentences) < 2:
            return context
        
        improved_sentences = [sentences[0]]  # Keep first sentence as-is
        
        transition_words = ['Furthermore', 'Additionally', 'Moreover', 'In addition', 'Similarly']
        
        for i, sentence in enumerate(sentences[1:], 1):
            # Add transition if sentence doesn't already have one
            # 如果句子还没有过渡词，则添加一个
            sentence_lower = sentence.lower()
            has_transition = any(word.lower() in sentence_lower[:20] for word in transition_words + ['however', 'therefore', 'consequently'])
            
            if not has_transition and len(sentence.split()) > 5:
                # Add appropriate transition
                # 添加适当的过渡
                if i == len(sentences) - 1:  # Last sentence
                    transition = "Finally"
                else:
                    transition = transition_words[i % len(transition_words)]
                
                sentence = f"{transition}, {sentence.lower()}"
            
            improved_sentences.append(sentence)
        
        return '. '.join(improved_sentences) + '.'
    
    def _remove_redundancy(self, context: str) -> str:
        """Remove redundant information"""
        """删除冗余信息"""
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        
        # Remove duplicate sentences
        # 删除重复的句子
        unique_sentences = []
        seen_sentences = set()
        
        for sentence in sentences:
            sentence_normalized = ' '.join(sentence.lower().split())  # Normalize whitespace
            if sentence_normalized not in seen_sentences:
                unique_sentences.append(sentence)
                seen_sentences.add(sentence_normalized)
        
        # Remove sentences that are subsets of other sentences
        # 删除是其他句子子集的句子
        filtered_sentences = []
        for i, sentence in enumerate(unique_sentences):
            is_redundant = False
            sentence_words = set(sentence.lower().split())
            
            for j, other_sentence in enumerate(unique_sentences):
                if i != j:
                    other_words = set(other_sentence.lower().split())
                    # If this sentence's words are a subset of another sentence
                    # 如果这个句子的词是另一个句子的子集
                    if sentence_words.issubset(other_words) and len(sentence_words) < len(other_words) * 0.8:
                        is_redundant = True
                        break
            
            if not is_redundant:
                filtered_sentences.append(sentence)
        
        return '. '.join(filtered_sentences) + '.'
    
    def _compress_verbose_sections(self, context: str) -> str:
        """Compress overly verbose sections"""
        """压缩过于冗长的部分"""
        sentences = [s.strip() for s in context.split('.') if s.strip()]
        
        compressed_sentences = []
        for sentence in sentences:
            words = sentence.split()
            
            # Compress sentences longer than 25 words
            # 压缩超过 25 个单词的句子
            if len(words) > 25:
                # Keep first part and last part, compress middle
                # 保留第一部分和最后一部分，压缩中间部分
                compressed = ' '.join(words[:10]) + ' ... ' + ' '.join(words[-10:])
                compressed_sentences.append(compressed)
            else:
                compressed_sentences.append(sentence)
        
        return '. '.join(compressed_sentences) + '.'
    
    def _update_learning(self, actions_applied: List[str], improvement: float):
        """Update learning based on action effectiveness"""
        """根据行动有效性更新学习"""
        for action_desc in actions_applied:
            # Extract action type from description (simplified)
            # 从描述中提取操作类型（简化）
            if "Add information" in action_desc:
                action_type = "add_missing_information"
            elif "Remove" in action_desc:
                action_type = "remove_irrelevant_content"
            elif "transitions" in action_desc:
                action_type = "add_transitions"
            elif "redundancy" in action_desc:
                action_type = "remove_redundancy"
            else:
                action_type = "general_improvement"
            
            # Update effectiveness tracking
            # 更新有效性跟踪
            current_effectiveness = self.strategy_effectiveness.get(action_type, 0.5)
            # Simple exponential moving average
            # 简单指数移动平均
            self.strategy_effectiveness[action_type] = 0.7 * current_effectiveness + 0.3 * min(1.0, improvement * 5)
    
    def _generate_refinement_report(self, history: List[Dict], initial: QualityAssessment, 
                                  final: QualityAssessment) -> Dict:
        """Generate comprehensive refinement report"""
        """生成综合优化报告"""
        
        total_iterations = len(history) - 1
        total_improvement = final.overall_score - initial.overall_score
        
        dimension_improvements = {
            'relevance': final.relevance_score - initial.relevance_score,
            'completeness': final.completeness_score - initial.completeness_score,
            'coherence': final.coherence_score - initial.coherence_score,
            'efficiency': final.efficiency_score - initial.efficiency_score
        }
        
        most_improved_dimension = max(dimension_improvements, key=dimension_improvements.get)
        
        all_actions = []
        for iteration in history[1:]:  # Skip initial state
            all_actions.extend(iteration.get('actions_taken', []))
        
        return {
            'summary': {
                'total_iterations': total_iterations,
                'initial_score': initial.overall_score,
                'final_score': final.overall_score,
                'total_improvement': total_improvement,
                'threshold_achieved': final.overall_score >= self.quality_threshold
            },
            'dimension_analysis': {
                'improvements': dimension_improvements,
                'most_improved': most_improved_dimension,
                'final_scores': {
                    'relevance': final.relevance_score,
                    'completeness': final.completeness_score,
                    'coherence': final.coherence_score,
                    'efficiency': final.efficiency_score
                }
            },
            'process_analysis': {
                'actions_applied': all_actions,
                'unique_action_types': len(set(all_actions)),
                'average_improvement_per_iteration': total_improvement / max(total_iterations, 1)
            },
            'learning_insights': {
                'strategy_effectiveness': dict(self.strategy_effectiveness),
                'refinement_patterns': self._analyze_refinement_patterns(history)
            }
        }
    
    def _analyze_refinement_patterns(self, history: List[Dict]) -> Dict:
        """Analyze patterns in the refinement process"""
        """分析优化过程中的模式"""
        patterns = {
            'convergence_rate': 'steady',
            'primary_focus': 'balanced',
            'efficiency_trend': 'improving'
        }
        
        if len(history) > 2:
            improvements = [iteration.get('improvement', 0) for iteration in history[1:]]
            
            # Analyze convergence rate
            # 分析收敛速度
            if len(improvements) > 1:
                if improvements[-1] < improvements[0] * 0.5:
                    patterns['convergence_rate'] = 'fast'
                elif improvements[-1] > improvements[0] * 0.8:
                    patterns['convergence_rate'] = 'slow'
            
            # Analyze primary focus based on actions
            # 根据行动分析主要重点
            all_actions = []
            for iteration in history[1:]: 
                all_actions.extend(iteration.get('actions_taken', []))
            
            if len(all_actions) > 0:
                if sum(1 for action in all_actions if 'Add' in action) > len(all_actions) / 2:
                    patterns['primary_focus'] = 'completeness'
                elif sum(1 for action in all_actions if 'Remove' in action) > len(all_actions) / 2:
                    patterns['primary_focus'] = 'efficiency'
                elif sum(1 for action in all_actions if 'flow' in action or 'transition' in action) > len(all_actions) / 2:
                    patterns['primary_focus'] = 'coherence'
        
        return patterns

# Example usage and demonstration
# 示例用法和演示
def demonstrate_self_refinement():
    """Demonstrate the self-refinement system with examples"""
    """用示例演示自我优化系统"""
    print("Demonstrating Self-Refinement System")
    print("=" * 50)
    
    # Initialize refinement engine
    # 初始化优化引擎
    refinement_engine = SelfRefinementEngine(quality_threshold=0.85, max_iterations=4)
    
    # Example context with quality issues
    # 存在质量问题的示例文本
    initial_context = """
    Machine learning is a type of artificial intelligence. Machine learning algorithms can learn from data. 
    They are very useful. Machine learning is used in many applications. It can be applied to various domains.
    The weather is nice today. Machine learning models require training data. Training data is important.
    Machine learning can solve complex problems. It is a powerful technology.
    """
    
    # Task definition
    # 任务定义
    task = "Explain what machine learning is, how it works, and provide specific examples of applications."
    
    print(f"Task: {task}")
    print(f"Initial context:\n{initial_context}")
    print("\n" + "=" * 50)
    
    # Perform refinement
    # 执行优化
    refined_context, final_assessment, report = refinement_engine.refine_context(
        initial_context, task
    )
    
    print("\n" + "=" * 50)
    print("REFINEMENT RESULTS")
    print("=" * 50)
    
    print(f"Refined context:\n{refined_context}")
    
    print(f"\nFinal Quality Assessment:")
    print(f"  Relevance: {final_assessment.relevance_score:.3f}")
    print(f"  Completeness: {final_assessment.completeness_score:.3f}")
    print(f"  Coherence: {final_assessment.coherence_score:.3f}")
    print(f"  Efficiency: {final_assessment.efficiency_score:.3f}")
    print(f"  Overall: {final_assessment.overall_score:.3f}")
    print(f"  Confidence: {final_assessment.confidence:.3f}")
    
    print(f"\nRefinement Report Summary:")
    summary = report['summary']
    print(f"  Iterations: {summary['total_iterations']}")
    print(f"  Improvement: {summary['total_improvement']:+.3f}")
    print(f"  Threshold achieved: {summary['threshold_achieved']}")
    
    print(f"\nDimension Improvements:")
    for dim, improvement in report['dimension_analysis']['improvements'].items():
        print(f"  {dim.capitalize()}: {improvement:+.3f}")
    
    print(f"\nMost improved dimension: {report['dimension_analysis']['most_improved']}")
    
    return refined_context, final_assessment, report

# Run demonstration
# 运行演示
if __name__ == "__main__":
    demonstrate_self_refinement()
```

**Ground-up Explanation**: This self-refinement engine works like having a skilled editor who systematically reviews and improves writing through multiple drafts. The system evaluates context across four key dimensions (relevance, completeness, coherence, efficiency), identifies specific problems, applies targeted improvements, and learns from what works. Like a master editor, it knows when to stop improving (convergence detection) and gets better at editing over time (meta-learning).
**基础解释**: 这个自我优化引擎就像一个熟练的编辑，通过多轮草稿系统地审阅和改进写作。该系统从四个关键维度（相关性、完整性、连贯性、效率）评估上下文，识别具体问题，应用有针对性的改进，并从有效的方法中学习。就像一位大师级编辑，它知道何时停止改进（收敛检测），并随着时间的推移在编辑方面做得更好（元学习）。

---

## Software 3.0 Paradigm 3: Protocols (Adaptive Refinement Shells) (软件 3.0 范式 3：协议 (自适应优化外壳))

Protocols provide self-modifying refinement patterns that evolve based on effectiveness.

协议提供了基于有效性演进的自我修改优化模式。

### Meta-Learning Refinement Protocol (元学习优化协议)

```
/refine.meta_learning{
    intent="Continuously improve refinement strategies through experience and pattern recognition",
    intent="通过经验和模式识别持续改进优化策略",
    
    input={
        refinement_history=<historical_refinement_sessions_and_outcomes>,
        current_context=<context_to_be_refined>,
        task_requirements=<specific_task_needs_and_success_criteria>,
        performance_targets=<quality_thresholds_and_optimization_goals>
    },
    
    process=[
        /analyze.historical_patterns{
            action="Extract successful refinement patterns from experience",
            action="从经验中提取成功的优化模式",
            method="Pattern mining across refinement sessions",
            method="跨优化会话的模式挖掘",
            analysis_dimensions=[
                {context_characteristics="identify_common_features_of_contexts_that_benefit_from_specific_refinements"},
                {task_type_correlations="map_task_types_to_most_effective_refinement_strategies"},
                {refinement_sequences="discover_optimal_order_for_applying_different_improvements"},
                {convergence_patterns="understand_when_refinements_reach_diminishing_returns"}
            ],
            pattern_extraction=[
                {successful_strategies="refinement_approaches_with_highest_success_rates"},
                {failure_modes="common_ways_refinement_attempts_fail_or_backfire"},
                {efficiency_optimizations="strategies_that_achieve_good_results_with_minimal_iterations"},
                {quality_predictors="early_indicators_of_refinement_success_or_failure"}
            ]
        },
        
        /predict.refinement_strategy{
            action="Predict optimal refinement approach for current context",
            action="预测当前上下文的最佳优化方法",
            method="Machine learning on historical refinement data",
            method="对历史优化数据进行机器学习",
            prediction_factors=[
                {context_similarity="how_similar_is_current_context_to_previously_refined_contexts"},
                {task_alignment="how_well_do_historical_task_patterns_match_current_requirements"},
                {quality_gap_analysis="what_quality_dimensions_most_need_improvement"},
                {resource_constraints="available_time_and_computational_budget_for_refinement"}
            ],
            strategy_selection=[
                {conservative_approach="minimal_high_confidence_improvements_with_low_risk"},
                {aggressive_approach="comprehensive_restructuring_for_maximum_quality_gain"},
                {targeted_approach="focused_improvements_on_specific_quality_dimensions"},
                {exploratory_approach="try_novel_refinement_techniques_for_learning"}
            ]
        },
        
        /execute.adaptive_refinement{
            action="Apply selected refinement strategy with real-time adaptation",
            action="应用选定的优化策略并进行实时调整",
            method="Dynamic strategy execution with performance monitoring",
            method="具有性能监控的动态策略执行",
            execution_monitoring=[
                {quality_tracking="continuous_assessment_of_refinement_progress"},
                {strategy_effectiveness="real_time_evaluation_of_chosen_approach"},
                {adaptation_triggers="conditions_that_warrant_strategy_modification"},
                {convergence_detection="recognition_of_optimal_stopping_point"}
            ],
            adaptive_mechanisms=[
                {strategy_switching="change_approach_if_current_strategy_underperforms"},
                {parameter_tuning="adjust_refinement_parameters_based_on_intermediate_results"},
                {early_termination="stop_refinement_if_quality_targets_achieved_early"},
                {emergency_rollback="revert_changes_if_refinement_degrades_context_quality"}
            ]
        },
        
        /learn.from_outcomes{
            action="Update refinement knowledge based on session results",
            action="根据会话结果更新优化知识",
            method="Experience integration and strategy calibration",
            method="经验整合和策略校准",
            learning_updates=[
                {strategy_effectiveness_calibration="update_confidence_in_different_refinement_approaches"},
                {pattern_recognition_enhancement="improve_ability_to_recognize_context_and_task_patterns"},
                {quality_prediction_improvement="enhance_accuracy_of_quality_outcome_predictions"},
                {efficiency_optimization="learn_to_achieve_better_results_with_fewer_iterations"}
            ],
            knowledge_integration=[
                {successful_pattern_storage="add_effective_patterns_to_strategy_library"},
                {failure_pattern_avoidance="update_failure_mode_detection_and_prevention"},
                {cross_context_transfer="apply_insights_from_one_context_type_to_others"},
                {meta_strategy_evolution="improve_the_refinement_strategy_selection_process_本身"}
            ]
        }
    ],
    
    output={
        refined_context=<optimally_improved_context>,
        refinement_metadata={
            strategy_used=<selected_and_executed_refinement_approach>,
            iterations_completed=<number_of_refinement_cycles>,
            quality_progression=<quality_scores_across_iterations>,
            adaptation_events=<times_strategy_was_modified_during_execution>
        },
        learning_integration={
            new_patterns_discovered=<novel_refinement_patterns_identified>,
            strategy_effectiveness_updates=<confidence_adjustments_in_different_approaches>,
            knowledge_base_enhancements=<additions_to_refinement_strategy_library>,
            meta_learning_insights=<improvements_to_the_learning_process_itself>
        }
    },
    
    meta={
        refinement_evolution=<how_refinement_capabilities_have_improved_over_time>,
        predictive_accuracy=<how_well_strategy_predictions_matched_actual_outcomes>,
        learning_velocity=<rate_of_improvement_in_refinement_effectiveness>,
        knowledge_transfer=<success_in_applying_learned_patterns_to_new_contexts>
    },
    
    // Self-evolution mechanisms for the refinement process itself
    // 优化过程本身的自我进化机制
    meta_refinement=[
        {trigger="refinement_strategy_consistently_underperforms", 
         action="experiment_with_novel_refinement_approaches"},
        {trigger="new_context_or_task_types_encountered", 
         action="develop_specialized_refinement_strategies"},
        {trigger="quality_prediction_accuracy_declining", 
         action="recalibrate_quality_assessment_mechanisms"},
        {trigger="learning_velocity_decreasing", 
         action="enhance_pattern_recognition_and_knowledge_integration_algorithms"}
    ]
}
```

**Ground-up Explanation**: This protocol creates a system that learns to learn better - like a master craftsperson who not only improves individual pieces of work but continuously refines their approach to improvement itself. The system recognizes patterns in what works, predicts the best approach for new situations, adapts in real-time based on results, and evolves its refinement capabilities over time.
**基础解释**: 该协议创建了一个能够学习如何更好地学习的系统——就像一位大师级工匠，他不仅改进单个作品，而且不断完善其改进方法本身。该系统能够识别有效模式，预测新情况下的最佳方法，根据结果实时调整，并随着时间的推移发展其优化能力。

---

## Research Connections and Future Directions (研究联系与未来方向)

### Connection to Context Engineering Survey (与上下文工程综述的联系)

This self-refinement module directly implements and extends key concepts from the [Context Engineering Survey](https://arxiv.org/pdf/2507.13334):

这个自我优化模块直接实现并扩展了[上下文工程综述](https://arxiv.org/pdf/2507.13334)中的关键概念：

**Self-Refinement Systems (Referenced throughout)** (自我优化系统 (全文引用)):
- Implements Self-Refine and Reflexion approaches with systematic quality evaluation (通过系统质量评估实现 Self-Refine 和 Reflexion 方法)
- Extends self-refinement beyond simple error correction to comprehensive quality optimization (将自我优化从简单的纠错扩展到全面的质量优化)
- Addresses iterative improvement challenges through convergence detection and meta-learning (通过收敛检测和元学习解决迭代改进的挑战)

**Context Management Integration (§4.3)** (上下文管理集成 (§4.3)):
- Implements context compression and quality optimization as unified process (将上下文压缩和质量优化实现为统一过程)
- Addresses context window management through efficient refinement strategies (通过高效的优化策略解决上下文窗口管理问题)
- Extends activation refilling concepts to quality-driven context enhancement (将激活填充概念扩展到质量驱动的上下文增强)

**Evaluation Framework Extensions (§6)** (评估框架扩展 (§6)):
- Develops multi-dimensional quality assessment beyond current evaluation approaches (开发超越当前评估方法的多维质量评估)
- Creates systematic refinement evaluation that addresses brittleness assessment needs (创建解决脆弱性评估需求的系统性优化评估)
- Implements contextual calibration through confidence-aware quality measurement (通过置信度感知的质量测量实现上下文校准)

---

## Advanced Self-Refinement Applications (高级自我优化应用)

### Collaborative Refinement Networks (协作优化网络)

```python
class CollaborativeRefinementNetwork:
    """Network of refinement agents that learn from each other"""
    """相互学习的优化智能体网络"""
    
    def __init__(self, num_agents: int = 3):
        self.agents = [SelfRefinementEngine() for _ in range(num_agents)]
        self.collaboration_history = []
        self.consensus_mechanisms = ConsensusBuilder()
        
    def collaborative_refine(self, context: str, task: str) -> Tuple[str, Dict]:
        """Refine context using multiple agents with consensus building"""
        """使用多个智能体和共识构建来优化上下文"""
        
        print(f"Starting collaborative refinement with {len(self.agents)} agents...")
        
        # Each agent independently refines the context
        # 每个智能体独立地优化上下文
        individual_results = []
        for i, agent in enumerate(self.agents):
            print(f"Agent {i+1} refining...")
            refined_context, assessment, report = agent.refine_context(context, task)
            individual_results.append({
                'agent_id': i,
                'refined_context': refined_context,
                'assessment': assessment,
                'report': report
            })
        
        # Build consensus from individual results
        # 从个体结果中建立共识
        consensus_result = self.consensus_mechanisms.build_consensus(
            individual_results, task
        )
        
        # Cross-agent learning
        # 跨智能体学习
        self._facilitate_cross_learning(individual_results, consensus_result)
        
        return consensus_result['final_context'], consensus_result['metadata']
    
    def _facilitate_cross_learning(self, individual_results: List[Dict], consensus: Dict):
        """Enable agents to learn from each other's strategies"""
        """使智能体能够相互学习策略"""
        
        # Identify most successful strategies
        # 识别最成功的策略
        best_agent = max(individual_results, 
                        key=lambda r: r['assessment'].overall_score)
        
        # Share successful patterns with other agents
        # 与其他智能体分享成功模式
        successful_patterns = best_agent['report']['learning_insights']['strategy_effectiveness']
        
        for i, agent in enumerate(self.agents):
            if i != best_agent['agent_id']:
                # Update agent's knowledge with successful patterns
                # 用成功模式更新智能体的知识
                for strategy, effectiveness in successful_patterns.items():
                    current_effectiveness = agent.strategy_effectiveness.get(strategy, 0.5)
                    # Weighted update incorporating peer learning
                    # 包含同伴学习的加权更新
                    agent.strategy_effectiveness[strategy] = (
                        0.7 * current_effectiveness + 0.3 * effectiveness
                    )

class ConsensusBuilder:
    """Builds consensus from multiple refinement attempts"""
    """从多次优化尝试中建立共识"""
    
    def build_consensus(self, results: List[Dict], task: str) -> Dict:
        """Build consensus refined context from multiple agent results"""
        """从多个智能体结果中建立共识优化上下文"""
        
        # Evaluate each result
        # 评估每个结果
        scored_results = []
        for result in results:
            score = self._evaluate_result_quality(result, task)
            scored_results.append((score, result))
```
        
        # Sort by quality
        scored_results.sort(reverse=True, key=lambda x: x[0])
        
        # Use top result as base, incorporate insights from others
        best_result = scored_results[0][1]
        final_context = self._integrate_multiple_perspectives(
            [r[1] for r in scored_results], task
        )
        
        return {
            'final_context': final_context,
            'metadata': {
                'consensus_quality': scored_results[0][0],
                'individual_scores': [s for s, _ in scored_results],
                'integration_method': 'weighted_synthesis'
            }
        }
    
    def _evaluate_result_quality(self, result: Dict, task: str) -> float:
        """Evaluate quality of individual refinement result"""
        assessment = result['assessment']
        report = result['report']
        
        # Base quality from assessment
        base_quality = assessment.overall_score
        
        # Bonus for efficiency (fewer iterations = better)
        efficiency_bonus = max(0, (5 - report['summary']['total_iterations']) * 0.02)
        
        # Bonus for high confidence
        confidence_bonus = assessment.confidence * 0.1
        
        return base_quality + efficiency_bonus + confidence_bonus
    
    def _integrate_multiple_perspectives(self, results: List[Dict], task: str) -> str:
        """Integrate insights from multiple refinement attempts"""
        # Start with best result
        base_context = results[0]['refined_context']
        
        # Extract unique insights from other results
        unique_insights = []
        base_sentences = set(base_context.split('.'))
        
        for result in results[1:]:
            other_sentences = set(result['refined_context'].split('.'))
            unique = other_sentences - base_sentences
            unique_insights.extend([s.strip() for s in unique if len(s.strip()) > 10])
        
        # Integrate valuable unique insights
        if unique_insights:
            # Simple integration - add most relevant insights
            relevant_insights = self._filter_relevant_insights(unique_insights, task, base_context)
            if relevant_insights:
                base_context += " " + " ".join(relevant_insights)
        
        return base_context
    
    def _filter_relevant_insights(self, insights: List[str], task: str, base_context: str) -> List[str]:
        """Filter insights for relevance and non-redundancy"""
        task_terms = set(task.lower().split())
        base_terms = set(base_context.lower().split())
        
        relevant = []
        for insight in insights:
            insight_terms = set(insight.lower().split())
            
            # Check relevance to task
            relevance = len(insight_terms & task_terms) / len(task_terms)
            
            # Check non-redundancy with base
            novelty = len(insight_terms - base_terms) / len(insight_terms)
            
            if relevance > 0.1 and novelty > 0.3:
                relevant.append(insight)
        
        return relevant[:2]  # Limit to top 2 insights
```

### Adaptive Quality Threshold System

```python
class AdaptiveQualityThresholds:
    """Dynamically adjust quality thresholds based on task importance and context"""
    
    def __init__(self):
        self.task_importance_factors = {
            'critical': 1.2,
            'high': 1.1, 
            'medium': 1.0,
            'low': 0.9
        }
        self.context_complexity_adjustments = {}
        self.historical_performance = []
        
    def calculate_adaptive_threshold(self, base_threshold: float, task: str, 
                                   context: str, importance: str = 'medium') -> float:
        """Calculate adaptive quality threshold based on multiple factors"""
        
        # Base adjustment for task importance
        importance_multiplier = self.task_importance_factors.get(importance, 1.0)
        adjusted_threshold = base_threshold * importance_multiplier
        
        # Adjust based on task complexity
        task_complexity = self._assess_task_complexity(task)
        complexity_adjustment = (task_complexity - 5) * 0.02  # Scale around medium complexity
        
        # Adjust based on context characteristics
        context_difficulty = self._assess_context_difficulty(context)
        difficulty_adjustment = (context_difficulty - 5) * 0.015
        
        # Historical performance adjustment
        historical_adjustment = self._get_historical_adjustment()
        
        final_threshold = adjusted_threshold + complexity_adjustment + difficulty_adjustment + historical_adjustment
        
        # Constrain to reasonable bounds
        return max(0.6, min(0.95, final_threshold))
    
    def _assess_task_complexity(self, task: str) -> int:
        """Assess task complexity on 1-10 scale"""
        complexity = 5  # Base medium complexity
        
        task_lower = task.lower()
        
        # Multi-step tasks increase complexity
        if 'analyze and compare' in task_lower or 'evaluate and recommend' in task_lower:
            complexity += 2
        
        # Multiple requirements increase complexity
        requirement_indicators = ['also', 'additionally', 'furthermore', 'moreover']
        complexity += sum(1 for indicator in requirement_indicators if indicator in task_lower)
        
        # Domain-specific tasks may be more complex
        domain_indicators = ['technical', 'scientific', 'legal', 'medical']
        if any(domain in task_lower for domain in domain_indicators):
            complexity += 1
        
        return min(10, complexity)
    
    def _assess_context_difficulty(self, context: str) -> int:
        """Assess context processing difficulty on 1-10 scale"""
        difficulty = 5  # Base medium difficulty
        
        # Length-based adjustment
        word_count = len(context.split())
        if word_count > 500:
            difficulty += 2
        elif word_count > 200:
            difficulty += 1
        elif word_count < 50:
            difficulty -= 1
        
        # Complexity-based adjustment
        unique_words = len(set(context.lower().split()))
        vocabulary_diversity = unique_words / max(word_count, 1)
        if vocabulary_diversity > 0.7:
            difficulty += 1
        
        # Technical content increases difficulty
        technical_indicators = ['algorithm', 'methodology', 'framework', 'implementation']
        if sum(1 for term in technical_indicators if term in context.lower()) > 2:
            difficulty += 1
        
        return min(10, max(1, difficulty))
    
    def _get_historical_adjustment(self) -> float:
        """Get adjustment based on historical performance"""
        if len(self.historical_performance) < 5:
            return 0.0
        
        recent_performance = self.historical_performance[-10:]
        avg_performance = sum(recent_performance) / len(recent_performance)
        
        # If historical performance is good, slightly lower threshold
        # If historical performance is poor, slightly raise threshold
        return (0.8 - avg_performance) * 0.1
    
    def record_performance(self, achieved_quality: float, target_threshold: float):
        """Record performance for historical adjustment"""
        performance_ratio = achieved_quality / target_threshold
        self.historical_performance.append(min(1.2, performance_ratio))
        
        # Keep only recent history
        if len(self.historical_performance) > 50:
            self.historical_performance = self.historical_performance[-50:]

# Comprehensive Evaluation and Assessment
class RefinementEvaluationSuite:
    """Comprehensive evaluation framework for self-refinement systems"""
    
    def __init__(self):
        self.evaluation_metrics = {
            'effectiveness': self._evaluate_effectiveness,
            'efficiency': self._evaluate_efficiency,
            'consistency': self._evaluate_consistency,
            'learning_capability': self._evaluate_learning_capability,
            'robustness': self._evaluate_robustness
        }
        
    def comprehensive_evaluation(self, refinement_engine: SelfRefinementEngine, 
                                test_cases: List[Dict]) -> Dict:
        """Perform comprehensive evaluation of refinement system"""
        
        print("Starting comprehensive refinement evaluation...")
        results = {}
        
        for metric_name, metric_function in self.evaluation_metrics.items():
            print(f"Evaluating {metric_name}...")
            metric_result = metric_function(refinement_engine, test_cases)
            results[metric_name] = metric_result
        
        # Calculate overall performance score
        results['overall_performance'] = self._calculate_overall_performance(results)
        
        # Generate improvement recommendations
        results['recommendations'] = self._generate_improvement_recommendations(results)
        
        return results
    
    def _evaluate_effectiveness(self, engine: SelfRefinementEngine, test_cases: List[Dict]) -> Dict:
        """Evaluate how effectively the system improves context quality"""
        improvements = []
        final_qualities = []
        
        for test_case in test_cases:
            initial_context = test_case['context']
            task = test_case['task']
            
            # Get initial quality
            initial_assessment = engine.assess_quality(initial_context, task)
            
            # Perform refinement
            refined_context, final_assessment, _ = engine.refine_context(initial_context, task)
            
            improvement = final_assessment.overall_score - initial_assessment.overall_score
            improvements.append(improvement)
            final_qualities.append(final_assessment.overall_score)
        
        return {
            'average_improvement': np.mean(improvements),
            'improvement_consistency': 1 - np.std(improvements),
            'average_final_quality': np.mean(final_qualities),
            'success_rate': sum(1 for imp in improvements if imp > 0.02) / len(improvements)
        }
    
    def _evaluate_efficiency(self, engine: SelfRefinementEngine, test_cases: List[Dict]) -> Dict:
        """Evaluate computational efficiency of refinement process"""
        iterations_used = []
        processing_times = []
        improvement_per_iteration = []
        
        for test_case in test_cases:
            start_time = time.time()
            
            initial_assessment = engine.assess_quality(test_case['context'], test_case['task'])
            refined_context, final_assessment, report = engine.refine_context(
                test_case['context'], test_case['task']
            )
            
            processing_time = time.time() - start_time
            iterations = report['summary']['total_iterations']
            total_improvement = report['summary']['total_improvement']
            
            iterations_used.append(iterations)
            processing_times.append(processing_time)
            
            if iterations > 0:
                improvement_per_iteration.append(total_improvement / iterations)
            else:
                improvement_per_iteration.append(0)
        
        return {
            'average_iterations': np.mean(iterations_used),
            'average_processing_time': np.mean(processing_times),
            'improvement_efficiency': np.mean(improvement_per_iteration),
            'convergence_rate': sum(1 for it in iterations_used if it < engine.max_iterations) / len(iterations_used)
        }
    
    def _evaluate_consistency(self, engine: SelfRefinementEngine, test_cases: List[Dict]) -> Dict:
        """Evaluate consistency of refinement results"""
        # Test same context multiple times
        consistency_scores = []
        
        for test_case in test_cases[:5]:  # Test subset for consistency
            results = []
            for _ in range(3):  # Multiple runs
                _, assessment, _ = engine.refine_context(test_case['context'], test_case['task'])
                results.append(assessment.overall_score)
            
            # Calculate coefficient of variation
            if np.mean(results) > 0:
                cv = np.std(results) / np.mean(results)
                consistency_scores.append(1 - cv)  # Higher consistency = lower variation
            else:
                consistency_scores.append(0)
        
        return {
            'average_consistency': np.mean(consistency_scores),
            'consistency_reliability': min(consistency_scores) if consistency_scores else 0
        }
    
    def _evaluate_learning_capability(self, engine: SelfRefinementEngine, test_cases: List[Dict]) -> Dict:
        """Evaluate system's ability to learn and improve over time"""
        # Track performance improvement over sequential test cases
        performance_over_time = []
        
        for i, test_case in enumerate(test_cases):
            _, assessment, report = engine.refine_context(test_case['context'], test_case['task'])
            
            # Measure learning indicators
            strategy_diversity = len(engine.strategy_effectiveness)
            average_strategy_confidence = np.mean(list(engine.strategy_effectiveness.values())) if engine.strategy_effectiveness else 0.5
            
            performance_over_time.append({
                'iteration': i,
                'quality_achieved': assessment.overall_score,
                'strategy_diversity': strategy_diversity,
                'average_confidence': average_strategy_confidence
            })
        
        # Analyze trends
        qualities = [p['quality_achieved'] for p in performance_over_time]
        confidences = [p['average_confidence'] for p in performance_over_time]
        
        # Simple linear trend analysis
        quality_trend = np.polyfit(range(len(qualities)), qualities, 1)[0] if len(qualities) > 1 else 0
        confidence_trend = np.polyfit(range(len(confidences)), confidences, 1)[0] if len(confidences) > 1 else 0
        
        return {
            'quality_improvement_trend': quality_trend,
            'confidence_growth_trend': confidence_trend,
            'strategy_diversity': performance_over_time[-1]['strategy_diversity'],
            'learning_evidence': quality_trend > 0 and confidence_trend > 0
        }
    
    def _evaluate_robustness(self, engine: SelfRefinementEngine, test_cases: List[Dict]) -> Dict:
        """Evaluate robustness across different context and task types"""
        performance_by_category = {}
        
        for test_case in test_cases:
            category = test_case.get('category', 'general')
            
            if category not in performance_by_category:
                performance_by_category[category] = []
            
            initial_assessment = engine.assess_quality(test_case['context'], test_case['task'])
            _, final_assessment, _ = engine.refine_context(test_case['context'], test_case['task'])
            
            improvement = final_assessment.overall_score - initial_assessment.overall_score
            performance_by_category[category].append(improvement)
        
        # Calculate robustness metrics
        category_performances = {
            cat: np.mean(improvements) 
            for cat, improvements in performance_by_category.items()
        }
        
        performance_variance = np.var(list(category_performances.values()))
        min_performance = min(category_performances.values())
        
        return {
            'performance_by_category': category_performances,
            'cross_category_consistency': 1 - performance_variance,
            'worst_case_performance': min_performance,
            'robustness_score': min_performance * (1 - performance_variance)
        }
    
    def _calculate_overall_performance(self, results: Dict) -> float:
        """Calculate weighted overall performance score"""
        weights = {
            'effectiveness': 0.3,
            'efficiency': 0.2,
            'consistency': 0.2,
            'learning_capability': 0.15,
            'robustness': 0.15
        }
        
        overall_score = 0
        for metric, weight in weights.items():
            if metric in results:
                metric_score = self._extract_primary_metric_score(metric, results[metric])
                overall_score += weight * metric_score
        
        return overall_score
    
    def _extract_primary_metric_score(self, metric_name: str, metric_results: Dict) -> float:
        """Extract primary score from metric results"""
        primary_keys = {
            'effectiveness': 'average_improvement',
            'efficiency': 'improvement_efficiency', 
            'consistency': 'average_consistency',
            'learning_capability': 'quality_improvement_trend',
            'robustness': 'robustness_score'
        }
        
        key = primary_keys.get(metric_name, list(metric_results.keys())[0])
        score = metric_results.get(key, 0.5)
        
        # Normalize to 0-1 range if needed
        if metric_name == 'learning_capability':
            score = max(0, min(1, score * 10))  # Scale trend to 0-1
        
        return max(0, min(1, score))
    
    def _generate_improvement_recommendations(self, results: Dict) -> List[str]:
        """Generate specific recommendations for improvement"""
        recommendations = []
        
        effectiveness = results.get('effectiveness', {})
        if effectiveness.get('success_rate', 0) < 0.8:
            recommendations.append("Improve refinement strategies - success rate below 80%")
        
        efficiency = results.get('efficiency', {})
        if efficiency.get('average_iterations', 0) > 3:
            recommendations.append("Optimize for faster convergence - too many iterations needed")
        
        consistency = results.get('consistency', {})
        if consistency.get('average_consistency', 0) < 0.7:
            recommendations.append("Improve consistency - results vary too much between runs")
        
        learning = results.get('learning_capability', {})
        if not learning.get('learning_evidence', False):
            recommendations.append("Enhance learning mechanisms - no clear improvement over time")
        
        robustness = results.get('robustness', {})
        if robustness.get('cross_category_consistency', 0) < 0.6:
            recommendations.append("Improve robustness across different context types")
        
        return recommendations

# Example comprehensive evaluation
def run_comprehensive_evaluation():
    """Run comprehensive evaluation of self-refinement system"""
    
    # Create test cases
    test_cases = [
        {
            'context': 'AI is useful. It has many applications. Machine learning is part of AI.',
            'task': 'Explain artificial intelligence, its key components, and provide specific examples',
            'category': 'explanation'
        },
        {
            'context': 'Company A is good. Company B is also good. Both companies are profitable.',
            'task': 'Compare Company A and Company B across multiple dimensions',
            'category': 'comparison'
        },
        {
            'context': 'The results show positive outcomes. The methodology was sound. Further research is needed.',
            'task': 'Analyze the research findings and evaluate their significance',
            'category': 'analysis'
        },
        {
            'context': 'Climate change is happening. It affects the environment. Action is needed.',
            'task': 'Evaluate different approaches to addressing climate change',
            'category': 'evaluation'
        }
    ]
    
    # Initialize systems
    refinement_engine = SelfRefinementEngine(quality_threshold=0.8, max_iterations=4)
    evaluation_suite = RefinementEvaluationSuite()
    
    # Run evaluation
    results = evaluation_suite.comprehensive_evaluation(refinement_engine, test_cases)
    
    print("\nCOMPREHENSIVE EVALUATION RESULTS")
    print("=" * 50)
    
    for metric, result in results.items():
        if metric not in ['recommendations', 'overall_performance']:
            print(f"\n{metric.upper()}:")
            if isinstance(result, dict):
                for key, value in result.items():
                    if isinstance(value, (int, float)):
                        print(f"  {key}: {value:.3f}")
                    else:
                        print(f"  {key}: {value}")
            else:
                print(f"  Score: {result:.3f}")
    
    print(f"\nOVERALL PERFORMANCE: {results['overall_performance']:.3f}")
    
    if results['recommendations']:
        print(f"\nRECOMMENDATIONS:")
        for i, rec in enumerate(results['recommendations'], 1):
            print(f"  {i}. {rec}")
    
    return results

# Run demonstration
if __name__ == "__main__":
    run_comprehensive_evaluation()
```

---

## Summary and Next Steps

**Core Concepts Mastered**:
- Iterative quality optimization through systematic refinement cycles
- Multi-dimensional context assessment (relevance, completeness, coherence, efficiency)
- Meta-cognitive monitoring and self-aware improvement processes
- Adaptive learning systems that improve refinement strategies over time

**Software 3.0 Integration**:
- **Prompts**: Quality assessment templates and meta-cognitive monitoring frameworks
- **Programming**: Self-refinement engines with learning and adaptation capabilities
- **Protocols**: Meta-learning refinement systems that evolve their own improvement strategies

**Implementation Skills**:
- Quality evaluators for systematic context assessment
- Iterative refinement engines with convergence detection
- Collaborative refinement networks for consensus building
- Comprehensive evaluation frameworks for refinement system assessment

**Research Grounding**: Direct implementation of self-refinement research with novel extensions into meta-cognitive monitoring, collaborative refinement, and adaptive quality thresholds.

**Next Module**: [03_multimodal_context.md](03_multimodal_context.md) - Building on self-refinement capabilities to explore cross-modal context integration, where systems must refine and optimize context across text, images, audio, and other modalities simultaneously.

---

*This module demonstrates the evolution from static context assembly to self-improving systems, embodying the Software 3.0 principle of systems that not only optimize context but continuously enhance their own optimization processes through meta-learning and self-reflection.*
